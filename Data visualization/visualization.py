# -*- coding: utf-8 -*-
"""visualization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13zpLOqEjdEFzJ3Af_fjHHkUbXmyM-B1m

# Import numpy, pandas, and matplotlib.pyplot
"""

import numpy as np

import pandas as pd

import matplotlib.pyplot as plt

import matplotlib.ticker as tick

"""# Read the final_dataset csv file"""

from google.colab import drive
drive.mount('/content/drive')

final_dts = pd.read_csv ('/content/drive/MyDrive/Colab Notebooks/final-project-dataset/final_dataset.csv')
final_dts

final_dts.info()

"""# **Visualizations**

# Q6 and Q25(a, b, c, d, e, f, g, h, i, and j)-  rate of emotions felt based on the field of study

Field Study: Arts

Emotion: Joyful
"""

first = final_dts[["Q6", "Q25a"]]
dfa_art = pd.DataFrame(first)
dfa_art.info()

art_joyful = dfa_art.loc[(dfa_art['Q6'] == 1) & (dfa_art['Q25a'] == 1)]
data_joyful_art = art_joyful.drop('Q6', axis = 1)
Data_joyful = data_joyful_art.value_counts()
art_data_joyful = Data_joyful.tolist()

art1_joyful = dfa_art.loc[(dfa_art['Q6'] == 1) & (dfa_art['Q25a'] == 2)]
data1_joyful_art = art1_joyful.drop('Q6', axis = 1)
Data1_joyful = data1_joyful_art.value_counts()
art_data1_joyful = Data1_joyful.tolist()

art2_joyful = dfa_art.loc[(dfa_art['Q6'] == 1) & (dfa_art['Q25a'] == 3)]
data2_joyful_art = art2_joyful.drop('Q6', axis = 1)
Data2_joyful = data2_joyful_art.value_counts()
art_data2_joyful = Data2_joyful.tolist()

art3_joyful = dfa_art.loc[(dfa_art['Q6'] == 1) & (dfa_art['Q25a'] == 4)]
data3_joyful_art = art3_joyful.drop('Q6', axis = 1)
Data3_joyful = data3_joyful_art.value_counts()
art_data3_joyful = Data3_joyful.tolist()

art4_joyful = dfa_art.loc[(dfa_art['Q6'] == 1) & (dfa_art['Q25a'] == 5)]
data4_joyful_art = art4_joyful.drop('Q6', axis = 1)
Data4_joyful = data4_joyful_art.value_counts()
art_data4_joyful = Data4_joyful.tolist()

"""Emotion: Hopeful"""

second = final_dts[["Q6", "Q25b"]]
dfb_art = pd.DataFrame(second)
dfb_art.info()

art_hopeful = dfb_art.loc[(dfb_art['Q6'] == 1) & (dfb_art['Q25b'] == 1)]
data_hopeful = art_hopeful.drop('Q6', axis = 1)
Data_hopeful = data_hopeful.value_counts()
art_data_hopeful = Data_hopeful.tolist()

art1_hopeful = dfb_art.loc[(dfb_art['Q6'] == 1) & (dfb_art['Q25b'] == 2)]
data1_hopeful = art1_hopeful.drop('Q6', axis = 1)
Data1_hopeful = data1_hopeful.value_counts()
art_data1_hopeful = Data1_hopeful.tolist()

art2_hopeful = dfb_art.loc[(dfb_art['Q6'] == 1) & (dfb_art['Q25b'] == 3)]
data2_hopeful = art2_hopeful.drop('Q6', axis = 1)
Data2_hopeful = data2_hopeful.value_counts()
art_data2_hopeful = Data2_hopeful.tolist()

art3_hopeful = dfb_art.loc[(dfb_art['Q6'] == 1) & (dfb_art['Q25b'] == 4)]
data3_hopeful = art3_hopeful.drop('Q6', axis = 1)
Data3_hopeful = data3_hopeful.value_counts()
art_data3_hopeful = Data3_hopeful.tolist()

art4_hopeful = dfb_art.loc[(dfb_art['Q6'] == 1) & (dfb_art['Q25b'] == 5)]
data4_hopeful = art4_hopeful.drop('Q6', axis = 1)
Data4_hopeful = data4_hopeful.value_counts()
art_data4_hopeful = Data4_hopeful.tolist()

"""Emotion: Proud"""

third = final_dts[["Q6", "Q25c"]]
dfc_art = pd.DataFrame(third)
dfc_art.info()

art_proud = dfc_art.loc[(dfc_art['Q6'] == 1) & (dfc_art['Q25c'] == 1)]
data_proud = art_proud.drop('Q6', axis = 1)
Data_proud = data_proud.value_counts()
art_data_proud = Data_proud.tolist()

art1_proud = dfc_art.loc[(dfc_art['Q6'] == 1) & (dfc_art['Q25c'] == 2)]
data1_proud = art1_proud.drop('Q6', axis = 1)
Data1_proud = data1_proud.value_counts()
art_data1_proud = Data1_proud.tolist()

art2_proud = dfc_art.loc[(dfc_art['Q6'] == 1) & (dfc_art['Q25c'] == 3)]
data2_proud = art2_proud.drop('Q6', axis = 1)
Data2_proud = data2_proud.value_counts()
art_data2_proud = Data2_proud.tolist()

art3_proud = dfc_art.loc[(dfc_art['Q6'] == 1) & (dfc_art['Q25c'] == 4)]
data3_proud = art3_proud.drop('Q6', axis = 1)
Data3_proud = data3_proud.value_counts()
art_data3_proud = Data3_proud.tolist()

art4_proud = dfc_art.loc[(dfc_art['Q6'] == 1) & (dfc_art['Q25c'] == 5)]
data4_proud = art4_proud.drop('Q6', axis = 1)
Data4_proud = data4_proud.value_counts()
art_data4_proud = Data4_proud.tolist()

"""Emotion: Frustrated"""

fourth = final_dts[["Q6", "Q25d"]]
dfd_art = pd.DataFrame(fourth)
dfd_art.info()

art_frustrated = dfd_art.loc[(dfd_art['Q6'] == 1) & (dfd_art['Q25d'] == 1)]
data_frustrated = art_frustrated.drop('Q6', axis = 1)
Data_frustrated = data_frustrated.value_counts()
art_data_frustrated = Data_frustrated.tolist()

art1_frustrated = dfd_art.loc[(dfd_art['Q6'] == 1) & (dfd_art['Q25d'] == 2)]
data1_frustrated = art1_frustrated.drop('Q6', axis = 1)
Data1_frustrated = data1_frustrated.value_counts()
art_data1_frustrated = Data1_frustrated.tolist()

art2_frustrated = dfd_art.loc[(dfd_art['Q6'] == 1) & (dfd_art['Q25d'] == 3)]
data2_frustrated = art2_frustrated.drop('Q6', axis = 1)
Data2_frustrated = data2_frustrated.value_counts()
art_data2_frustrated = Data2_frustrated.tolist()

art3_frustrated = dfd_art.loc[(dfd_art['Q6'] == 1) & (dfd_art['Q25d'] == 4)]
data3_frustrated = art3_frustrated.drop('Q6', axis = 1)
Data3_frustrated = data3_frustrated.value_counts()
art_data3_frustrated = Data3_frustrated.tolist()

art4_frustrated = dfd_art.loc[(dfd_art['Q6'] == 1) & (dfd_art['Q25d'] == 5)]
data4_frustrated = art4_frustrated.drop('Q6', axis = 1)
Data4_frustrated = data4_frustrated.value_counts()
art_data4_frustrated = Data4_frustrated.tolist()

"""Emotion: Angry"""

fifth = final_dts[["Q6", "Q25e"]]
dfe_art = pd.DataFrame(fifth)
dfe_art.info()

art_angry = dfe_art.loc[(dfe_art['Q6'] == 1) & (dfe_art['Q25e'] == 1)]
data_angry = art_angry.drop('Q6', axis = 1)
Data_angry = data_angry.value_counts()
art_data_angry = Data_angry.tolist()

art1_angry = dfe_art.loc[(dfe_art['Q6'] == 1) & (dfe_art['Q25e'] == 2)]
data1_angry = art1_angry.drop('Q6', axis = 1)
Data1_angry = data1_angry.value_counts()
art_data1_angry = Data1_angry.tolist()

art2_angry = dfe_art.loc[(dfe_art['Q6'] == 1) & (dfe_art['Q25e'] == 3)]
data2_angry = art2_angry.drop('Q6', axis = 1)
Data2_angry = data2_angry.value_counts()
art_data2_angry = Data2_angry.tolist()

art3_angry = dfe_art.loc[(dfe_art['Q6'] == 1) & (dfe_art['Q25e'] == 4)]
data3_angry = art3_angry.drop('Q6', axis = 1)
Data3_angry = data3_angry.value_counts()
art_data3_angry = Data3_angry.tolist()

art4_angry = dfe_art.loc[(dfe_art['Q6'] == 1) & (dfe_art['Q25e'] == 5)]
data4_angry = art4_angry.drop('Q6', axis = 1)
Data4_angry = data4_angry.value_counts()
art_data4_angry = Data4_angry.tolist()

"""Emotion: Anxious"""

sixth = final_dts[["Q6", "Q25f"]]
dff_art = pd.DataFrame(sixth)
dff_art.info()

art_anxious = dff_art.loc[(dff_art['Q6'] == 1) & (dff_art['Q25f'] == 1)]
data_anxious = art_anxious.drop('Q6', axis = 1)
Data_anxious = data_anxious.value_counts()
art_data_anxious = Data_anxious.tolist()

art1_anxious = dff_art.loc[(dff_art['Q6'] == 1) & (dff_art['Q25f'] == 2)]
data1_anxious = art1_anxious.drop('Q6', axis = 1)
Data1_anxious = data1_anxious.value_counts()
art_data1_anxious = Data1_anxious.tolist()

art2_anxious = dff_art.loc[(dff_art['Q6'] == 1) & (dff_art['Q25f'] == 3)]
data2_anxious = art2_anxious.drop('Q6', axis = 1)
Data2_anxious = data2_anxious.value_counts()
art_data2_anxious = Data2_anxious.tolist()

art3_anxious = dff_art.loc[(dff_art['Q6'] == 1) & (dff_art['Q25f'] == 4)]
data3_anxious = art3_anxious.drop('Q6', axis = 1)
Data3_anxious = data3_anxious.value_counts()
art_data3_anxious = Data3_anxious.tolist()

art4_anxious = dff_art.loc[(dff_art['Q6'] == 1) & (dff_art['Q25f'] == 5)]
data4_anxious = art4_anxious.drop('Q6', axis = 1)
Data4_anxious = data4_anxious.value_counts()
art_data4_anxious = Data4_anxious.tolist()

"""Emotion: Ashamed"""

seventh = final_dts[["Q6", "Q25g"]]
dfg_art = pd.DataFrame(seventh)
dfg_art.info()

art_ashamed = dfg_art.loc[(dfg_art['Q6'] == 1) & (dfg_art['Q25g'] == 1)]
data_ashamed = art_ashamed.drop('Q6', axis = 1)
Data_ashamed = data_ashamed.value_counts()
art_data_ashamed = Data_ashamed.tolist()

art1_ashamed = dfg_art.loc[(dfg_art['Q6'] == 1) & (dfg_art['Q25g'] == 2)]
data1_ashamed = art1_ashamed.drop('Q6', axis = 1)
Data1_ashamed = data1_ashamed.value_counts()
art_data1_ashamed = Data1_ashamed.tolist()

art2_ashamed = dfg_art.loc[(dfg_art['Q6'] == 1) & (dfg_art['Q25g'] == 3)]
data2_ashamed = art2_ashamed.drop('Q6', axis = 1)
Data2_ashamed = data2_ashamed.value_counts()
art_data2_ashamed = Data2_ashamed.tolist()

art3_ashamed = dfg_art.loc[(dfg_art['Q6'] == 1) & (dfg_art['Q25g'] == 4)]
data3_ashamed = art3_ashamed.drop('Q6', axis = 1)
Data3_ashamed = data3_ashamed.value_counts()
art_data3_ashamed = Data3_ashamed.tolist()

art4_ashamed = dfg_art.loc[(dfg_art['Q6'] == 1) & (dfg_art['Q25g'] == 5)]
data4_ashamed = art4_ashamed.drop('Q6', axis = 1)
Data4_ashamed = data4_ashamed.value_counts()
art_data4_ashamed = Data4_ashamed.tolist()

"""Emotion: Relieved"""

eighth = final_dts[["Q6", "Q25h"]]
dfh_art = pd.DataFrame(eighth)
dfh_art.info()

art_relieved = dfh_art.loc[(dfh_art['Q6'] == 1) & (dfh_art['Q25h'] == 1)]
data_relieved = art_relieved.drop('Q6', axis = 1)
Data_relieved = data_relieved.value_counts()
art_data_relieved = Data_relieved.tolist()

art1_relieved = dfh_art.loc[(dfh_art['Q6'] == 1) & (dfh_art['Q25h'] == 2)]
data1_relieved = art1_relieved.drop('Q6', axis = 1)
Data1_relieved = data1_relieved.value_counts()
art_data1_relieved = Data1_relieved.tolist()

art2_relieved = dfh_art.loc[(dfh_art['Q6'] == 1) & (dfh_art['Q25h'] == 3)]
data2_relieved = art2_relieved.drop('Q6', axis = 1)
Data2_relieved = data2_relieved.value_counts()
art_data2_relieved = Data2_relieved.tolist()

art3_relieved = dfh_art.loc[(dfh_art['Q6'] == 1) & (dfh_art['Q25h'] == 4)]
data3_relieved = art3_relieved.drop('Q6', axis = 1)
Data3_relieved = data3_relieved.value_counts()
art_data3_relieved = Data3_relieved.tolist()

art4_relieved = dfh_art.loc[(dfh_art['Q6'] == 1) & (dfh_art['Q25h'] == 5)]
data4_relieved = art4_relieved.drop('Q6', axis = 1)
Data4_relieved = data4_relieved.value_counts()
art_data4_relieved = Data4_relieved.tolist()

"""Emotion: Hopeless"""

ninth = final_dts[["Q6", "Q25i"]]
dfi_art = pd.DataFrame(ninth)
dfi_art.info()

art_hopeless = dfi_art.loc[(dfi_art['Q6'] == 1) & (dfi_art['Q25i'] == 1)]
data_hopeless = art_hopeless.drop('Q6', axis = 1)
Data_hopeless = data_hopeless.value_counts()
art_data_hopeless = Data_hopeless.tolist()

art1_hopeless = dfi_art.loc[(dfi_art['Q6'] == 1) & (dfi_art['Q25i'] == 2)]
data1_hopeless = art1_hopeless.drop('Q6', axis = 1)
Data1_hopeless = data1_hopeless.value_counts()
art_data1_hopeless = Data1_hopeless.tolist()

art2_hopeless = dfi_art.loc[(dfi_art['Q6'] == 1) & (dfi_art['Q25i'] == 3)]
data2_hopeless = art2_hopeless.drop('Q6', axis = 1)
Data2_hopeless = data2_hopeless.value_counts()
art_data2_hopeless = Data2_hopeless.tolist()

art3_hopeless = dfi_art.loc[(dfi_art['Q6'] == 1) & (dfi_art['Q25i'] == 4)]
data3_hopeless = art3_hopeless.drop('Q6', axis = 1)
Data3_hopeless = data3_hopeless.value_counts()
art_data3_hopeless = Data3_hopeless.tolist()

art4_hopeless = dfi_art.loc[(dfi_art['Q6'] == 1) & (dfi_art['Q25i'] == 5)]
data4_hopeless = art4_hopeless.drop('Q6', axis = 1)
Data4_hopeless = data4_hopeless.value_counts()
art_data4_hopeless = Data4_hopeless.tolist()

"""Emotion: Bored"""

tenth = final_dts[["Q6", "Q25j"]]
dfj_art = pd.DataFrame(tenth)
dfj_art.info()

art_bored = dfj_art.loc[(dfj_art['Q6'] == 1) & (dfj_art['Q25j'] == 1)]
data_bored = art_bored.drop('Q6', axis = 1)
Data_bored = data_bored.value_counts()
art_data_bored = Data_bored.tolist()

art1_bored = dfj_art.loc[(dfj_art['Q6'] == 1) & (dfj_art['Q25j'] == 2)]
data1_bored = art1_bored.drop('Q6', axis = 1)
Data1_bored = data1_bored.value_counts()
art_data1_bored = Data1_bored.tolist()

art2_bored = dfj_art.loc[(dfj_art['Q6'] == 1) & (dfj_art['Q25j'] == 3)]
data2_bored = art2_bored.drop('Q6', axis = 1)
Data2_bored = data2_bored.value_counts()
art_data2_bored = Data2_bored.tolist()

art3_bored = dfj_art.loc[(dfj_art['Q6'] == 1) & (dfj_art['Q25j'] == 4)]
data3_bored = art3_bored.drop('Q6', axis = 1)
Data3_bored = data3_bored.value_counts()
art_data3_bored = Data3_bored.tolist()

art4_bored = dfj_art.loc[(dfj_art['Q6'] == 1) & (dfj_art['Q25j'] == 5)]
data4_bored = art4_bored.drop('Q6', axis = 1)
Data4_bored = data4_bored.value_counts()
art_data4_bored = Data4_bored.tolist()

"""Field Study: Social

Emotion: Joyful
"""

first = final_dts[["Q6", "Q25a"]]
dfa_social = pd.DataFrame(first)
dfa_social.info()


social_joyful = dfa_social.loc[(dfa_social['Q6'] == 2) & (dfa_social['Q25a'] == 1)]
data_joyful_social = social_joyful.drop('Q6', axis = 1)
Data_joyful = data_joyful_social.value_counts()
social_data_joyful = Data_joyful.tolist()

social1_joyful = dfa_social.loc[(dfa_social['Q6'] == 2) & (dfa_social['Q25a'] == 2)]
data1_joyful_social = social1_joyful.drop('Q6', axis = 1)
Data1_joyful = data1_joyful_social.value_counts()
social_data1_joyful = Data1_joyful.tolist()

social2_joyful = dfa_social.loc[(dfa_social['Q6'] == 2) & (dfa_social['Q25a'] == 3)]
data2_joyful_social = social2_joyful.drop('Q6', axis = 1)
Data2_joyful = data2_joyful_social.value_counts()
social_data2_joyful = Data2_joyful.tolist()

social3_joyful = dfa_social.loc[(dfa_social['Q6'] == 2) & (dfa_social['Q25a'] == 4)]
data3_joyful_social = social3_joyful.drop('Q6', axis = 1)
Data3_joyful = data3_joyful_social.value_counts()
social_data3_joyful = Data3_joyful.tolist()

social4_joyful = dfa_social.loc[(dfa_social['Q6'] == 2) & (dfa_social['Q25a'] == 5)]
data4_joyful_social = social4_joyful.drop('Q6', axis = 1)
Data4_joyful = data4_joyful_social.value_counts()
social_data4_joyful = Data4_joyful.tolist()

"""Emotion: Hopeful"""

second = final_dts[["Q6", "Q25b"]]
dfb_social = pd.DataFrame(second)
dfb_social.info()

social_hopeful = dfb_social.loc[(dfb_social['Q6'] == 2) & (dfb_social['Q25b'] == 1)]
data_hopeful = social_hopeful.drop('Q6', axis = 1)
Data_hopeful = data_hopeful.value_counts()
social_data_hopeful = Data_hopeful.tolist()

social1_hopeful = dfb_social.loc[(dfb_social['Q6'] == 2) & (dfb_social['Q25b'] == 2)]
data1_hopeful = social1_hopeful.drop('Q6', axis = 1)
Data1_hopeful = data1_hopeful.value_counts()
social_data1_hopeful = Data1_hopeful.tolist()

social2_hopeful = dfb_social.loc[(dfb_social['Q6'] == 2) & (dfb_social['Q25b'] == 3)]
data2_hopeful = social2_hopeful.drop('Q6', axis = 1)
Data2_hopeful = data2_hopeful.value_counts()
social_data2_hopeful = Data2_hopeful.tolist()

social3_hopeful = dfb_social.loc[(dfb_social['Q6'] == 2) & (dfb_social['Q25b'] == 4)]
data3_hopeful = social3_hopeful.drop('Q6', axis = 1)
Data3_hopeful = data3_hopeful.value_counts()
social_data3_hopeful = Data3_hopeful.tolist()

social4_hopeful = dfb_social.loc[(dfb_social['Q6'] == 2) & (dfb_social['Q25b'] == 5)]
data4_hopeful = social4_hopeful.drop('Q6', axis = 1)
Data4_hopeful = data4_hopeful.value_counts()
social_data4_hopeful = Data4_hopeful.tolist()

"""Emotion: Proud"""

third = final_dts[["Q6", "Q25c"]]
dfc_social = pd.DataFrame(third)
dfc_social.info()

social_proud = dfc_social.loc[(dfc_social['Q6'] == 2) & (dfc_social['Q25c'] == 1)]
data_proud = social_proud.drop('Q6', axis = 1)
Data_proud = data_proud.value_counts()
social_data_proud = Data_proud.tolist()

social1_proud = dfc_social.loc[(dfc_social['Q6'] == 2) & (dfc_social['Q25c'] == 2)]
data1_proud = social1_proud.drop('Q6', axis = 1)
Data1_proud = data1_proud.value_counts()
social_data1_proud = Data1_proud.tolist()

social2_proud = dfc_social.loc[(dfc_social['Q6'] == 2) & (dfc_social['Q25c'] == 3)]
data2_proud = social2_proud.drop('Q6', axis = 1)
Data2_proud = data2_proud.value_counts()
social_data2_proud = Data2_proud.tolist()

social3_proud = dfc_social.loc[(dfc_social['Q6'] == 2) & (dfc_social['Q25c'] == 4)]
data3_proud = social3_proud.drop('Q6', axis = 1)
Data3_proud = data3_proud.value_counts()
social_data3_proud = Data3_proud.tolist()

social4_proud = dfc_social.loc[(dfc_social['Q6'] == 2) & (dfc_social['Q25c'] == 5)]
data4_proud = social4_proud.drop('Q6', axis = 1)
Data4_proud = data4_proud.value_counts()
social_data4_proud = Data4_proud.tolist()

"""Emotion: Frustrated"""

fourth = final_dts[["Q6", "Q25d"]]
dfd_social = pd.DataFrame(fourth)
dfd_social.info()

social_frustrated = dfd_social.loc[(dfd_social['Q6'] == 2) & (dfd_social['Q25d'] == 1)]
data_frustrated = social_frustrated.drop('Q6', axis = 1)
Data_frustrated = data_frustrated.value_counts()
social_data_frustrated = Data_frustrated.tolist()

social1_frustrated = dfd_social.loc[(dfd_social['Q6'] == 2) & (dfd_social['Q25d'] == 2)]
data1_frustrated = social1_frustrated.drop('Q6', axis = 1)
Data1_frustrated = data1_frustrated.value_counts()
social_data1_frustrated = Data1_frustrated.tolist()

social2_frustrated = dfd_social.loc[(dfd_social['Q6'] == 2) & (dfd_social['Q25d'] == 3)]
data2_frustrated = social2_frustrated.drop('Q6', axis = 1)
Data2_frustrated = data2_frustrated.value_counts()
social_data2_frustrated = Data2_frustrated.tolist()

social3_frustrated = dfd_social.loc[(dfd_social['Q6'] == 2) & (dfd_social['Q25d'] == 4)]
data3_frustrated = social3_frustrated.drop('Q6', axis = 1)
Data3_frustrated = data3_frustrated.value_counts()
social_data3_frustrated = Data3_frustrated.tolist()

social4_frustrated = dfd_social.loc[(dfd_social['Q6'] == 2) & (dfd_social['Q25d'] == 5)]
data4_frustrated = social4_frustrated.drop('Q6', axis = 1)
Data4_frustrated = data4_frustrated.value_counts()
social_data4_frustrated = Data4_frustrated.tolist()

"""Emotion: Angry"""

fifth = final_dts[["Q6", "Q25e"]]
dfe_social = pd.DataFrame(fifth)
dfe_social.info()

social_angry = dfe_social.loc[(dfe_social['Q6'] == 2) & (dfe_social['Q25e'] == 1)]
data_angry = social_angry.drop('Q6', axis = 1)
Data_angry = data_angry.value_counts()
social_data_angry = Data_angry.tolist()

social1_angry = dfe_social.loc[(dfe_social['Q6'] == 2) & (dfe_social['Q25e'] == 2)]
data1_angry = social1_angry.drop('Q6', axis = 1)
Data1_angry = data1_angry.value_counts()
social_data1_angry = Data1_angry.tolist()

social2_angry = dfe_social.loc[(dfe_social['Q6'] == 2) & (dfe_social['Q25e'] == 3)]
data2_angry = social2_angry.drop('Q6', axis = 1)
Data2_angry = data2_angry.value_counts()
social_data2_angry = Data2_angry.tolist()

social3_angry = dfe_social.loc[(dfe_social['Q6'] == 2) & (dfe_social['Q25e'] == 4)]
data3_angry = social3_angry.drop('Q6', axis = 1)
Data3_angry = data3_angry.value_counts()
social_data3_angry = Data3_angry.tolist()

social4_angry = dfe_social.loc[(dfe_social['Q6'] == 2) & (dfe_social['Q25e'] == 5)]
data4_angry = social4_angry.drop('Q6', axis = 1)
Data4_angry = data4_angry.value_counts()
social_data4_angry = Data4_angry.tolist()

"""Emotion: Anxious"""

sixth = final_dts[["Q6", "Q25f"]]
dff_social = pd.DataFrame(sixth)
dff_social.info()

social_anxious = dff_social.loc[(dff_social['Q6'] == 2) & (dff_social['Q25f'] == 1)]
data_anxious = social_anxious.drop('Q6', axis = 1)
Data_anxious = data_anxious.value_counts()
social_data_anxious = Data_anxious.tolist()

social1_anxious = dff_social.loc[(dff_social['Q6'] == 2) & (dff_social['Q25f'] == 2)]
data1_anxious = social1_anxious.drop('Q6', axis = 1)
Data1_anxious = data1_anxious.value_counts()
social_data1_anxious = Data1_anxious.tolist()

social2_anxious = dff_social.loc[(dff_social['Q6'] == 2) & (dff_social['Q25f'] == 3)]
data2_anxious = social2_anxious.drop('Q6', axis = 1)
Data2_anxious = data2_anxious.value_counts()
social_data2_anxious = Data2_anxious.tolist()

social3_anxious = dff_social.loc[(dff_social['Q6'] == 2) & (dff_social['Q25f'] == 4)]
data3_anxious = social3_anxious.drop('Q6', axis = 1)
Data3_anxious = data3_anxious.value_counts()
social_data3_anxious = Data3_anxious.tolist()

social4_anxious = dff_social.loc[(dff_social['Q6'] == 2) & (dff_social['Q25f'] == 5)]
data4_anxious = social4_anxious.drop('Q6', axis = 1)
Data4_anxious = data4_anxious.value_counts()
social_data4_anxious = Data4_anxious.tolist()

"""Emotion: Ashamed"""

seventh = final_dts[["Q6", "Q25g"]]
dfg_social = pd.DataFrame(seventh)
dfg_social.info()

social_ashamed = dfg_social.loc[(dfg_social['Q6'] == 2) & (dfg_social['Q25g'] == 1)]
data_ashamed = social_ashamed.drop('Q6', axis = 1)
Data_ashamed = data_ashamed.value_counts()
social_data_ashamed = Data_ashamed.tolist()

social1_ashamed = dfg_social.loc[(dfg_social['Q6'] == 2) & (dfg_social['Q25g'] == 2)]
data1_ashamed = social1_ashamed.drop('Q6', axis = 1)
Data1_ashamed = data1_ashamed.value_counts()
social_data1_ashamed = Data1_ashamed.tolist()

social2_ashamed = dfg_social.loc[(dfg_social['Q6'] == 2) & (dfg_social['Q25g'] == 3)]
data2_ashamed = social2_ashamed.drop('Q6', axis = 1)
Data2_ashamed = data2_ashamed.value_counts()
social_data2_ashamed = Data2_ashamed.tolist()

social3_ashamed = dfg_social.loc[(dfg_social['Q6'] == 2) & (dfg_social['Q25g'] == 4)]
data3_ashamed = social3_ashamed.drop('Q6', axis = 1)
Data3_ashamed = data3_ashamed.value_counts()
social_data3_ashamed = Data3_ashamed.tolist()

social4_ashamed = dfg_social.loc[(dfg_social['Q6'] == 2) & (dfg_social['Q25g'] == 5)]
data4_ashamed = social4_ashamed.drop('Q6', axis = 1)
Data4_ashamed = data4_ashamed.value_counts()
social_data4_ashamed = Data4_ashamed.tolist()

"""Emotion: Relieved"""

eighth = final_dts[["Q6", "Q25h"]]
dfh_social = pd.DataFrame(eighth)
dfh_social.info()

social_relieved = dfh_social.loc[(dfh_social['Q6'] == 2) & (dfh_social['Q25h'] == 1)]
data_relieved = social_relieved.drop('Q6', axis = 1)
Data_relieved = data_relieved.value_counts()
social_data_relieved = Data_relieved.tolist()

social1_relieved = dfh_social.loc[(dfh_social['Q6'] == 2) & (dfh_social['Q25h'] == 2)]
data1_relieved = social1_relieved.drop('Q6', axis = 1)
Data1_relieved = data1_relieved.value_counts()
social_data1_relieved = Data1_relieved.tolist()

social2_relieved = dfh_social.loc[(dfh_social['Q6'] == 2) & (dfh_social['Q25h'] == 3)]
data2_relieved = social2_relieved.drop('Q6', axis = 1)
Data2_relieved = data2_relieved.value_counts()
social_data2_relieved = Data2_relieved.tolist()

social3_relieved = dfh_social.loc[(dfh_social['Q6'] == 2) & (dfh_social['Q25h'] == 4)]
data3_relieved = social3_relieved.drop('Q6', axis = 1)
Data3_relieved = data3_relieved.value_counts()
social_data3_relieved = Data3_relieved.tolist()

social4_relieved = dfh_social.loc[(dfh_social['Q6'] == 2) & (dfh_social['Q25h'] == 5)]
data4_relieved = social4_relieved.drop('Q6', axis = 1)
Data4_relieved = data4_relieved.value_counts()
social_data4_relieved = Data4_relieved.tolist()

"""Emotion: Hopeless"""

ninth = final_dts[["Q6", "Q25i"]]
dfi_social = pd.DataFrame(ninth)
dfi_social.info()

social_hopeless = dfi_social.loc[(dfi_social['Q6'] == 2) & (dfi_social['Q25i'] == 1)]
data_hopeless = social_hopeless.drop('Q6', axis = 1)
Data_hopeless = data_hopeless.value_counts()
social_data_hopeless = Data_hopeless.tolist()

social1_hopeless = dfi_social.loc[(dfi_social['Q6'] == 2) & (dfi_social['Q25i'] == 2)]
data1_hopeless = social1_hopeless.drop('Q6', axis = 1)
Data1_hopeless = data1_hopeless.value_counts()
social_data1_hopeless = Data1_hopeless.tolist()

social2_hopeless = dfi_social.loc[(dfi_social['Q6'] == 2) & (dfi_social['Q25i'] == 3)]
data2_hopeless = social2_hopeless.drop('Q6', axis = 1)
Data2_hopeless = data2_hopeless.value_counts()
social_data2_hopeless = Data2_hopeless.tolist()

social3_hopeless = dfi_social.loc[(dfi_social['Q6'] == 2) & (dfi_social['Q25i'] == 4)]
data3_hopeless = social3_hopeless.drop('Q6', axis = 1)
Data3_hopeless = data3_hopeless.value_counts()
social_data3_hopeless = Data3_hopeless.tolist()

social4_hopeless = dfi_social.loc[(dfi_social['Q6'] == 2) & (dfi_social['Q25i'] == 5)]
data4_hopeless = social4_hopeless.drop('Q6', axis = 1)
Data4_hopeless = data4_hopeless.value_counts()
social_data4_hopeless = Data4_hopeless.tolist()

"""Emotion: Bored"""

tenth = final_dts[["Q6", "Q25j"]]
dfj_social = pd.DataFrame(tenth)
dfj_social.info()

social_bored = dfj_social.loc[(dfj_social['Q6'] == 2) & (dfj_social['Q25j'] == 1)]
data_bored = social_bored.drop('Q6', axis = 1)
Data_bored = data_bored.value_counts()
social_data_bored = Data_bored.tolist()

social1_bored = dfj_social.loc[(dfj_social['Q6'] == 2) & (dfj_social['Q25j'] == 2)]
data1_bored = social1_bored.drop('Q6', axis = 1)
Data1_bored = data1_bored.value_counts()
social_data1_bored = Data1_bored.tolist()

social2_bored = dfj_social.loc[(dfj_social['Q6'] == 2) & (dfj_social['Q25j'] == 3)]
data2_bored = social2_bored.drop('Q6', axis = 1)
Data2_bored = data2_bored.value_counts()
social_data2_bored = Data2_bored.tolist()

social3_bored = dfj_social.loc[(dfj_social['Q6'] == 2) & (dfj_social['Q25j'] == 4)]
data3_bored = social3_bored.drop('Q6', axis = 1)
Data3_bored = data3_bored.value_counts()
social_data3_bored = Data3_bored.tolist()

social4_bored = dfj_social.loc[(dfj_social['Q6'] == 2) & (dfj_social['Q25j'] == 5)]
data4_bored = social4_bored.drop('Q6', axis = 1)
Data4_bored = data4_bored.value_counts()
social_data4_bored = Data4_bored.tolist()

"""Field Study: Natural and Life Sciences

Emotion: Joyful
"""

first = final_dts[["Q6", "Q25a"]]
dfa_natural = pd.DataFrame(first)
dfa_natural.info()

natural_joyful = dfa_natural.loc[(dfa_natural['Q6'] == 3) & (dfa_natural['Q25a'] == 1)]
data_joyful_natural = natural_joyful.drop('Q6', axis = 1)
Data_joyful = data_joyful_natural.value_counts()
natural_data_joyful = Data_joyful.tolist()

natural1_joyful = dfa_natural.loc[(dfa_natural['Q6'] == 3) & (dfa_natural['Q25a'] == 2)]
data1_joyful_natural = natural1_joyful.drop('Q6', axis = 1)
Data1_joyful = data1_joyful_natural.value_counts()
natural_data1_joyful = Data1_joyful.tolist()

natural2_joyful = dfa_natural.loc[(dfa_natural['Q6'] == 3) & (dfa_natural['Q25a'] == 3)]
data2_joyful_natural = natural2_joyful.drop('Q6', axis = 1)
Data2_joyful = data2_joyful_natural.value_counts()
natural_data2_joyful = Data2_joyful.tolist()

natural3_joyful = dfa_natural.loc[(dfa_natural['Q6'] == 3) & (dfa_natural['Q25a'] == 4)]
data3_joyful_natural = natural3_joyful.drop('Q6', axis = 1)
Data3_joyful = data3_joyful_natural.value_counts()
natural_data3_joyful = Data3_joyful.tolist()

natural4_joyful = dfa_natural.loc[(dfa_natural['Q6'] == 3) & (dfa_natural['Q25a'] == 5)]
data4_joyful_natural = natural4_joyful.drop('Q6', axis = 1)
Data4_joyful = data4_joyful_natural.value_counts()
natural_data4_joyful = Data4_joyful.tolist()

"""Emotion: Hopeful"""

second = final_dts[["Q6", "Q25b"]]
dfb_natural = pd.DataFrame(second)
dfb_natural.info()

natural_hopeful = dfb_natural.loc[(dfb_natural['Q6'] == 3) & (dfb_natural['Q25b'] == 1)]
data_hopeful = natural_hopeful.drop('Q6', axis = 1)
Data_hopeful = data_hopeful.value_counts()
natural_data_hopeful = Data_hopeful.tolist()

natural1_hopeful = dfb_natural.loc[(dfb_natural['Q6'] == 3) & (dfb_natural['Q25b'] == 2)]
data1_hopeful = natural1_hopeful.drop('Q6', axis = 1)
Data1_hopeful = data1_hopeful.value_counts()
natural_data1_hopeful = Data1_hopeful.tolist()

natural2_hopeful = dfb_natural.loc[(dfb_natural['Q6'] == 3) & (dfb_natural['Q25b'] == 3)]
data2_hopeful = natural2_hopeful.drop('Q6', axis = 1)
Data2_hopeful = data2_hopeful.value_counts()
natural_data2_hopeful = Data2_hopeful.tolist()

natural3_hopeful = dfb_natural.loc[(dfb_natural['Q6'] == 3) & (dfb_natural['Q25b'] == 4)]
data3_hopeful = natural3_hopeful.drop('Q6', axis = 1)
Data3_hopeful = data3_hopeful.value_counts()
natural_data3_hopeful = Data3_hopeful.tolist()

natural4_hopeful = dfb_natural.loc[(dfb_natural['Q6'] == 3) & (dfb_natural['Q25b'] == 5)]
data4_hopeful = natural4_hopeful.drop('Q6', axis = 1)
Data4_hopeful = data4_hopeful.value_counts()
natural_data4_hopeful = Data4_hopeful.tolist()

"""Emotion: Proud"""

third = final_dts[["Q6", "Q25c"]]
dfc_natural = pd.DataFrame(third)
dfc_natural.info()

natural_proud = dfc_natural.loc[(dfc_natural['Q6'] == 3) & (dfc_natural['Q25c'] == 1)]
data_proud = natural_proud.drop('Q6', axis = 1)
Data_proud = data_proud.value_counts()
natural_data_proud = Data_proud.tolist()

natural1_proud = dfc_natural.loc[(dfc_natural['Q6'] == 3) & (dfc_natural['Q25c'] == 2)]
data1_proud = natural1_proud.drop('Q6', axis = 1)
Data1_proud = data1_proud.value_counts()
natural_data1_proud = Data1_proud.tolist()

natural2_proud = dfc_natural.loc[(dfc_natural['Q6'] == 3) & (dfc_natural['Q25c'] == 3)]
data2_proud = natural2_proud.drop('Q6', axis = 1)
Data2_proud = data2_proud.value_counts()
natural_data2_proud = Data2_proud.tolist()

natural3_proud = dfc_natural.loc[(dfc_natural['Q6'] == 3) & (dfc_natural['Q25c'] == 4)]
data3_proud = natural3_proud.drop('Q6', axis = 1)
Data3_proud = data3_proud.value_counts()
natural_data3_proud = Data3_proud.tolist()

natural4_proud = dfc_natural.loc[(dfc_natural['Q6'] == 3) & (dfc_natural['Q25c'] == 5)]
data4_proud = natural4_proud.drop('Q6', axis = 1)
Data4_proud = data4_proud.value_counts()
natural_data4_proud = Data4_proud.tolist()

"""Emotion: Frustrated"""

fourth = final_dts[["Q6", "Q25d"]]
dfd_natural = pd.DataFrame(fourth)
dfd_natural.info()

natural_frustrated = dfd_natural.loc[(dfd_natural['Q6'] == 3) & (dfd_natural['Q25d'] == 1)]
data_frustrated = natural_frustrated.drop('Q6', axis = 1)
Data_frustrated = data_frustrated.value_counts()
natural_data_frustrated = Data_frustrated.tolist()

natural1_frustrated = dfd_natural.loc[(dfd_natural['Q6'] == 3) & (dfd_natural['Q25d'] == 2)]
data1_frustrated = natural1_frustrated.drop('Q6', axis = 1)
Data1_frustrated = data1_frustrated.value_counts()
natural_data1_frustrated = Data1_frustrated.tolist()

natural2_frustrated = dfd_natural.loc[(dfd_natural['Q6'] == 3) & (dfd_natural['Q25d'] == 3)]
data2_frustrated = natural2_frustrated.drop('Q6', axis = 1)
Data2_frustrated = data2_frustrated.value_counts()
natural_data2_frustrated = Data2_frustrated.tolist()

natural3_frustrated = dfd_natural.loc[(dfd_natural['Q6'] == 3) & (dfd_natural['Q25d'] == 4)]
data3_frustrated = natural3_frustrated.drop('Q6', axis = 1)
Data3_frustrated = data3_frustrated.value_counts()
natural_data3_frustrated = Data3_frustrated.tolist()

natural4_frustrated = dfd_natural.loc[(dfd_natural['Q6'] == 3) & (dfd_natural['Q25d'] == 5)]
data4_frustrated = natural4_frustrated.drop('Q6', axis = 1)
Data4_frustrated = data4_frustrated.value_counts()
natural_data4_frustrated = Data4_frustrated.tolist()

"""Emotion: Angry"""

fifth = final_dts[["Q6", "Q25e"]]
dfe_natural = pd.DataFrame(fifth)
dfe_natural.info()

natural_angry = dfe_natural.loc[(dfe_natural['Q6'] == 3) & (dfe_natural['Q25e'] == 1)]
data_angry = natural_angry.drop('Q6', axis = 1)
Data_angry = data_angry.value_counts()
natural_data_angry = Data_angry.tolist()

natural1_angry = dfe_natural.loc[(dfe_natural['Q6'] == 3) & (dfe_natural['Q25e'] == 2)]
data1_angry = natural1_angry.drop('Q6', axis = 1)
Data1_angry = data1_angry.value_counts()
natural_data1_angry = Data1_angry.tolist()

natural2_angry = dfe_natural.loc[(dfe_natural['Q6'] == 3) & (dfe_natural['Q25e'] == 3)]
data2_angry = natural2_angry.drop('Q6', axis = 1)
Data2_angry = data2_angry.value_counts()
natural_data2_angry = Data2_angry.tolist()

natural3_angry = dfe_natural.loc[(dfe_natural['Q6'] == 3) & (dfe_natural['Q25e'] == 4)]
data3_angry = natural3_angry.drop('Q6', axis = 1)
Data3_angry = data3_angry.value_counts()
natural_data3_angry = Data3_angry.tolist()

natural4_angry = dfe_natural.loc[(dfe_natural['Q6'] == 3) & (dfe_natural['Q25e'] == 5)]
data4_angry = natural4_angry.drop('Q6', axis = 1)
Data4_angry = data4_angry.value_counts()
natural_data4_angry = Data4_angry.tolist()

"""Emotion: Anxious"""

sixth = final_dts[["Q6", "Q25f"]]
dff_natural = pd.DataFrame(sixth)
dff_natural.info()

natural_anxious = dff_natural.loc[(dff_natural['Q6'] == 3) & (dff_natural['Q25f'] == 1)]
data_anxious = natural_anxious.drop('Q6', axis = 1)
Data_anxious = data_anxious.value_counts()
natural_data_anxious = Data_anxious.tolist()

natural1_anxious = dff_natural.loc[(dff_natural['Q6'] == 3) & (dff_natural['Q25f'] == 2)]
data1_anxious = natural1_anxious.drop('Q6', axis = 1)
Data1_anxious = data1_anxious.value_counts()
natural_data1_anxious = Data1_anxious.tolist()

natural2_anxious = dff_natural.loc[(dff_natural['Q6'] == 3) & (dff_natural['Q25f'] == 3)]
data2_anxious = natural2_anxious.drop('Q6', axis = 1)
Data2_anxious = data2_anxious.value_counts()
natural_data2_anxious = Data2_anxious.tolist()

natural3_anxious = dff_natural.loc[(dff_natural['Q6'] == 3) & (dff_natural['Q25f'] == 4)]
data3_anxious = natural3_anxious.drop('Q6', axis = 1)
Data3_anxious = data3_anxious.value_counts()
natural_data3_anxious = Data3_anxious.tolist()

natural4_anxious = dff_natural.loc[(dff_natural['Q6'] == 3) & (dff_natural['Q25f'] == 5)]
data4_anxious = natural4_anxious.drop('Q6', axis = 1)
Data4_anxious = data4_anxious.value_counts()
natural_data4_anxious = Data4_anxious.tolist()

"""Emotion: Ashamed"""

seventh = final_dts[["Q6", "Q25g"]]
dfg_natural = pd.DataFrame(seventh)
dfg_natural.info()

natural_ashamed = dfg_natural.loc[(dfg_natural['Q6'] == 3) & (dfg_natural['Q25g'] == 1)]
data_ashamed = natural_ashamed.drop('Q6', axis = 1)
Data_ashamed = data_ashamed.value_counts()
natural_data_ashamed = Data_ashamed.tolist()

natural1_ashamed = dfg_natural.loc[(dfg_natural['Q6'] == 3) & (dfg_natural['Q25g'] == 2)]
data1_ashamed = natural1_ashamed.drop('Q6', axis = 1)
Data1_ashamed = data1_ashamed.value_counts()
natural_data1_ashamed = Data1_ashamed.tolist()

natural2_ashamed = dfg_natural.loc[(dfg_natural['Q6'] == 3) & (dfg_natural['Q25g'] == 3)]
data2_ashamed = natural2_ashamed.drop('Q6', axis = 1)
Data2_ashamed = data2_ashamed.value_counts()
natural_data2_ashamed = Data2_ashamed.tolist()

natural3_ashamed = dfg_natural.loc[(dfg_natural['Q6'] == 3) & (dfg_natural['Q25g'] == 4)]
data3_ashamed = natural3_ashamed.drop('Q6', axis = 1)
Data3_ashamed = data3_ashamed.value_counts()
natural_data3_ashamed = Data3_ashamed.tolist()

natural4_ashamed = dfg_natural.loc[(dfg_natural['Q6'] == 3) & (dfg_natural['Q25g'] == 5)]
data4_ashamed = natural4_ashamed.drop('Q6', axis = 1)
Data4_ashamed = data4_ashamed.value_counts()
natural_data4_ashamed = Data4_ashamed.tolist()

"""Emotion: Relieved"""

eighth = final_dts[["Q6", "Q25h"]]
dfh_natural = pd.DataFrame(eighth)
dfh_natural.info()

natural_relieved = dfh_natural.loc[(dfh_natural['Q6'] == 3) & (dfh_natural['Q25h'] == 1)]
data_relieved = natural_relieved.drop('Q6', axis = 1)
Data_relieved = data_relieved.value_counts()
natural_data_relieved = Data_relieved.tolist()

natural1_relieved = dfh_natural.loc[(dfh_natural['Q6'] == 3) & (dfh_natural['Q25h'] == 2)]
data1_relieved = natural1_relieved.drop('Q6', axis = 1)
Data1_relieved = data1_relieved.value_counts()
natural_data1_relieved = Data1_relieved.tolist()

natural2_relieved = dfh_natural.loc[(dfh_natural['Q6'] == 3) & (dfh_natural['Q25h'] == 3)]
data2_relieved = natural2_relieved.drop('Q6', axis = 1)
Data2_relieved = data2_relieved.value_counts()
natural_data2_relieved = Data2_relieved.tolist()

natural3_relieved = dfh_natural.loc[(dfh_natural['Q6'] == 3) & (dfh_natural['Q25h'] == 4)]
data3_relieved = natural3_relieved.drop('Q6', axis = 1)
Data3_relieved = data3_relieved.value_counts()
natural_data3_relieved = Data3_relieved.tolist()

natural4_relieved = dfh_natural.loc[(dfh_natural['Q6'] == 3) & (dfh_natural['Q25h'] == 5)]
data4_relieved = natural4_relieved.drop('Q6', axis = 1)
Data4_relieved = data4_relieved.value_counts()
natural_data4_relieved = Data4_relieved.tolist()

"""Emotion: Hopeless"""

ninth = final_dts[["Q6", "Q25i"]]
dfi_natural = pd.DataFrame(ninth)
dfi_natural.info()

natural_hopeless = dfi_natural.loc[(dfi_natural['Q6'] == 3) & (dfi_natural['Q25i'] == 1)]
data_hopeless = natural_hopeless.drop('Q6', axis = 1)
Data_hopeless = data_hopeless.value_counts()
natural_data_hopeless = Data_hopeless.tolist()

natural1_hopeless = dfi_natural.loc[(dfi_natural['Q6'] == 3) & (dfi_natural['Q25i'] == 2)]
data1_hopeless = natural1_hopeless.drop('Q6', axis = 1)
Data1_hopeless = data1_hopeless.value_counts()
natural_data1_hopeless = Data1_hopeless.tolist()

natural2_hopeless = dfi_natural.loc[(dfi_natural['Q6'] == 3) & (dfi_natural['Q25i'] == 3)]
data2_hopeless = natural2_hopeless.drop('Q6', axis = 1)
Data2_hopeless = data2_hopeless.value_counts()
natural_data2_hopeless = Data2_hopeless.tolist()

natural3_hopeless = dfi_natural.loc[(dfi_natural['Q6'] == 3) & (dfi_natural['Q25i'] == 4)]
data3_hopeless = natural3_hopeless.drop('Q6', axis = 1)
Data3_hopeless = data3_hopeless.value_counts()
natural_data3_hopeless = Data3_hopeless.tolist()

natural4_hopeless = dfi_natural.loc[(dfi_natural['Q6'] == 3) & (dfi_natural['Q25i'] == 5)]
data4_hopeless = natural4_hopeless.drop('Q6', axis = 1)
Data4_hopeless = data4_hopeless.value_counts()
natural_data4_hopeless = Data4_hopeless.tolist()

"""Emotion: Bored"""

tenth = final_dts[["Q6", "Q25j"]]
dfj_natural = pd.DataFrame(tenth)
dfj_natural.info()

natural_bored = dfj_natural.loc[(dfj_natural['Q6'] == 3) & (dfj_natural['Q25j'] == 1)]
data_bored = natural_bored.drop('Q6', axis = 1)
Data_bored = data_bored.value_counts()
natural_data_bored = Data_bored.tolist()

natural1_bored = dfj_natural.loc[(dfj_natural['Q6'] == 3) & (dfj_natural['Q25j'] == 2)]
data1_bored = natural1_bored.drop('Q6', axis = 1)
Data1_bored = data1_bored.value_counts()
natural_data1_bored = Data1_bored.tolist()

natural2_bored = dfj_natural.loc[(dfj_natural['Q6'] == 3) & (dfj_natural['Q25j'] == 3)]
data2_bored = natural2_bored.drop('Q6', axis = 1)
Data2_bored = data2_bored.value_counts()
natural_data2_bored = Data2_bored.tolist()

natural3_bored = dfj_natural.loc[(dfj_natural['Q6'] == 3) & (dfj_natural['Q25j'] == 4)]
data3_bored = natural3_bored.drop('Q6', axis = 1)
Data3_bored = data3_bored.value_counts()
natural_data3_bored = Data3_bored.tolist()

natural4_bored = dfj_natural.loc[(dfj_natural['Q6'] == 3) & (dfj_natural['Q25j'] == 5)]
data4_bored = natural4_bored.drop('Q6', axis = 1)
Data4_bored = data4_bored.value_counts()
natural_data4_bored = Data4_bored.tolist()

"""Field Study: Technical

Emotion: Joyful
"""

first = final_dts[["Q6", "Q25a"]]
dfa_technical = pd.DataFrame(first)
dfa_technical.info()

technical_joyful = dfa_technical.loc[(dfa_technical['Q6'] == 4) & (dfa_technical['Q25a'] == 1)]
data_joyful_technical = technical_joyful.drop('Q6', axis = 1)
Data_joyful = data_joyful_technical.value_counts()
technical_data_joyful = Data_joyful.tolist()

technical1_joyful = dfa_technical.loc[(dfa_technical['Q6'] == 4) & (dfa_technical['Q25a'] == 2)]
data1_joyful_technical = technical1_joyful.drop('Q6', axis = 1)
Data1_joyful = data1_joyful_technical.value_counts()
technical_data1_joyful = Data1_joyful.tolist()

technical2_joyful = dfa_technical.loc[(dfa_technical['Q6'] == 4) & (dfa_technical['Q25a'] == 3)]
data2_joyful_technical = technical2_joyful.drop('Q6', axis = 1)
Data2_joyful = data2_joyful_technical.value_counts()
technical_data2_joyful = Data2_joyful.tolist()

technical3_joyful = dfa_technical.loc[(dfa_technical['Q6'] == 4) & (dfa_technical['Q25a'] == 4)]
data3_joyful_technical = technical3_joyful.drop('Q6', axis = 1)
Data3_joyful = data3_joyful_technical.value_counts()
technical_data3_joyful = Data3_joyful.tolist()

technical4_joyful = dfa_technical.loc[(dfa_technical['Q6'] == 4) & (dfa_technical['Q25a'] == 5)]
data4_joyful_technical = technical4_joyful.drop('Q6', axis = 1)
Data4_joyful = data4_joyful_technical.value_counts()
technical_data4_joyful = Data4_joyful.tolist()

"""Emotion: Hopeful"""

second = final_dts[["Q6", "Q25b"]]
dfb_technical = pd.DataFrame(second)
dfb_technical.info()

technical_hopeful = dfb_technical.loc[(dfb_technical['Q6'] == 4) & (dfb_technical['Q25b'] == 1)]
data_hopeful = technical_hopeful.drop('Q6', axis = 1)
Data_hopeful = data_hopeful.value_counts()
technical_data_hopeful = Data_hopeful.tolist()

technical1_hopeful = dfb_technical.loc[(dfb_technical['Q6'] == 4) & (dfb_technical['Q25b'] == 2)]
data1_hopeful = technical1_hopeful.drop('Q6', axis = 1)
Data1_hopeful = data1_hopeful.value_counts()
technical_data1_hopeful = Data1_hopeful.tolist()

technical2_hopeful = dfb_technical.loc[(dfb_technical['Q6'] == 4) & (dfb_technical['Q25b'] == 3)]
data2_hopeful = technical2_hopeful.drop('Q6', axis = 1)
Data2_hopeful = data2_hopeful.value_counts()
technical_data2_hopeful = Data2_hopeful.tolist()

technical3_hopeful = dfb_technical.loc[(dfb_technical['Q6'] == 4) & (dfb_technical['Q25b'] == 4)]
data3_hopeful = technical3_hopeful.drop('Q6', axis = 1)
Data3_hopeful = data3_hopeful.value_counts()
technical_data3_hopeful = Data3_hopeful.tolist()

technical4_hopeful = dfb_technical.loc[(dfb_technical['Q6'] == 4) & (dfb_technical['Q25b'] == 5)]
data4_hopeful = technical4_hopeful.drop('Q6', axis = 1)
Data4_hopeful = data4_hopeful.value_counts()
technical_data4_hopeful = Data4_hopeful.tolist()

"""Emotion: Proud"""

third = final_dts[["Q6", "Q25c"]]
dfc_technical = pd.DataFrame(third)
dfc_technical.info()

technical_proud = dfc_technical.loc[(dfc_technical['Q6'] == 4) & (dfc_technical['Q25c'] == 1)]
data_proud = technical_proud.drop('Q6', axis = 1)
Data_proud = data_proud.value_counts()
technical_data_proud = Data_proud.tolist()

technical1_proud = dfc_technical.loc[(dfc_technical['Q6'] == 4) & (dfc_technical['Q25c'] == 2)]
data1_proud = technical1_proud.drop('Q6', axis = 1)
Data1_proud = data1_proud.value_counts()
technical_data1_proud = Data1_proud.tolist()

technical2_proud = dfc_technical.loc[(dfc_technical['Q6'] == 4) & (dfc_technical['Q25c'] == 3)]
data2_proud = technical2_proud.drop('Q6', axis = 1)
Data2_proud = data2_proud.value_counts()
technical_data2_proud = Data2_proud.tolist()

technical3_proud = dfc_technical.loc[(dfc_technical['Q6'] == 4) & (dfc_technical['Q25c'] == 4)]
data3_proud = technical3_proud.drop('Q6', axis = 1)
Data3_proud = data3_proud.value_counts()
technical_data3_proud = Data3_proud.tolist()

technical4_proud = dfc_technical.loc[(dfc_technical['Q6'] == 4) & (dfc_technical['Q25c'] == 5)]
data4_proud = technical4_proud.drop('Q6', axis = 1)
Data4_proud = data4_proud.value_counts()
technical_data4_proud = Data4_proud.tolist()

"""Emotion: Frustrated"""

fourth = final_dts[["Q6", "Q25d"]]
dfd_technical = pd.DataFrame(fourth)
dfd_technical.info()

technical_frustrated = dfd_technical.loc[(dfd_technical['Q6'] == 4) & (dfd_technical['Q25d'] == 1)]
data_frustrated = technical_frustrated.drop('Q6', axis = 1)
Data_frustrated = data_frustrated.value_counts()
technical_data_frustrated = Data_frustrated.tolist()

technical1_frustrated = dfd_technical.loc[(dfd_technical['Q6'] == 4) & (dfd_technical['Q25d'] == 2)]
data1_frustrated = technical1_frustrated.drop('Q6', axis = 1)
Data1_frustrated = data1_frustrated.value_counts()
technical_data1_frustrated = Data1_frustrated.tolist()

technical2_frustrated = dfd_technical.loc[(dfd_technical['Q6'] == 4) & (dfd_technical['Q25d'] == 3)]
data2_frustrated = technical2_frustrated.drop('Q6', axis = 1)
Data2_frustrated = data2_frustrated.value_counts()
technical_data2_frustrated = Data2_frustrated.tolist()

technical3_frustrated = dfd_technical.loc[(dfd_technical['Q6'] == 4) & (dfd_technical['Q25d'] == 4)]
data3_frustrated = technical3_frustrated.drop('Q6', axis = 1)
Data3_frustrated = data3_frustrated.value_counts()
technical_data3_frustrated = Data3_frustrated.tolist()

technical4_frustrated = dfd_technical.loc[(dfd_technical['Q6'] == 4) & (dfd_technical['Q25d'] == 5)]
data4_frustrated = technical4_frustrated.drop('Q6', axis = 1)
Data4_frustrated = data4_frustrated.value_counts()
technical_data4_frustrated = Data4_frustrated.tolist()

"""Emotion: Angry"""

fifth = final_dts[["Q6", "Q25e"]]
dfe_technical = pd.DataFrame(fifth)
dfe_technical.info()

technical_angry = dfe_technical.loc[(dfe_technical['Q6'] == 4) & (dfe_technical['Q25e'] == 1)]
data_angry = technical_angry.drop('Q6', axis = 1)
Data_angry = data_angry.value_counts()
technical_data_angry = Data_angry.tolist()

technical1_angry = dfe_technical.loc[(dfe_technical['Q6'] == 4) & (dfe_technical['Q25e'] == 2)]
data1_angry = technical1_angry.drop('Q6', axis = 1)
Data1_angry = data1_angry.value_counts()
technical_data1_angry = Data1_angry.tolist()

technical2_angry = dfe_technical.loc[(dfe_technical['Q6'] == 4) & (dfe_technical['Q25e'] == 3)]
data2_angry = technical2_angry.drop('Q6', axis = 1)
Data2_angry = data2_angry.value_counts()
technical_data2_angry = Data2_angry.tolist()

technical3_angry = dfe_technical.loc[(dfe_technical['Q6'] == 4) & (dfe_technical['Q25e'] == 4)]
data3_angry = technical3_angry.drop('Q6', axis = 1)
Data3_angry = data3_angry.value_counts()
technical_data3_angry = Data3_angry.tolist()

technical4_angry = dfe_technical.loc[(dfe_technical['Q6'] == 4) & (dfe_technical['Q25e'] == 5)]
data4_angry = technical4_angry.drop('Q6', axis = 1)
Data4_angry = data4_angry.value_counts()
technical_data4_angry = Data4_angry.tolist()

"""Emotion: Anxious"""

sixth = final_dts[["Q6", "Q25f"]]
dff_technical = pd.DataFrame(sixth)
dff_technical.info()

technical_anxious = dff_technical.loc[(dff_technical['Q6'] == 4) & (dff_technical['Q25f'] == 1)]
data_anxious = technical_anxious.drop('Q6', axis = 1)
Data_anxious = data_anxious.value_counts()
technical_data_anxious = Data_anxious.tolist()

technical1_anxious = dff_technical.loc[(dff_technical['Q6'] == 4) & (dff_technical['Q25f'] == 2)]
data1_anxious = technical1_anxious.drop('Q6', axis = 1)
Data1_anxious = data1_anxious.value_counts()
technical_data1_anxious = Data1_anxious.tolist()

technical2_anxious = dff_technical.loc[(dff_technical['Q6'] == 4) & (dff_technical['Q25f'] == 3)]
data2_anxious = technical2_anxious.drop('Q6', axis = 1)
Data2_anxious = data2_anxious.value_counts()
technical_data2_anxious = Data2_anxious.tolist()

technical3_anxious = dff_technical.loc[(dff_technical['Q6'] == 4) & (dff_technical['Q25f'] == 4)]
data3_anxious = technical3_anxious.drop('Q6', axis = 1)
Data3_anxious = data3_anxious.value_counts()
technical_data3_anxious = Data3_anxious.tolist()

technical4_anxious = dff_technical.loc[(dff_technical['Q6'] == 4) & (dff_technical['Q25f'] == 5)]
data4_anxious = technical4_anxious.drop('Q6', axis = 1)
Data4_anxious = data4_anxious.value_counts()
technical_data4_anxious = Data4_anxious.tolist()

"""Emotion: Ashamed"""

seventh = final_dts[["Q6", "Q25g"]]
dfg_technical = pd.DataFrame(seventh)
dfg_technical.info()

technical_ashamed = dfg_technical.loc[(dfg_technical['Q6'] == 4) & (dfg_technical['Q25g'] == 1)]
data_ashamed = technical_ashamed.drop('Q6', axis = 1)
Data_ashamed = data_ashamed.value_counts()
technical_data_ashamed = Data_ashamed.tolist()

technical1_ashamed = dfg_technical.loc[(dfg_technical['Q6'] == 4) & (dfg_technical['Q25g'] == 2)]
data1_ashamed = technical1_ashamed.drop('Q6', axis = 1)
Data1_ashamed = data1_ashamed.value_counts()
technical_data1_ashamed = Data1_ashamed.tolist()

technical2_ashamed = dfg_technical.loc[(dfg_technical['Q6'] == 4) & (dfg_technical['Q25g'] == 3)]
data2_ashamed = technical2_ashamed.drop('Q6', axis = 1)
Data2_ashamed = data2_ashamed.value_counts()
technical_data2_ashamed = Data2_ashamed.tolist()

technical3_ashamed = dfg_technical.loc[(dfg_technical['Q6'] == 4) & (dfg_technical['Q25g'] == 4)]
data3_ashamed = technical3_ashamed.drop('Q6', axis = 1)
Data3_ashamed = data3_ashamed.value_counts()
technical_data3_ashamed = Data3_ashamed.tolist()

technical4_ashamed = dfg_technical.loc[(dfg_technical['Q6'] == 4) & (dfg_technical['Q25g'] == 5)]
data4_ashamed = technical4_ashamed.drop('Q6', axis = 1)
Data4_ashamed = data4_ashamed.value_counts()
technical_data4_ashamed = Data4_ashamed.tolist()

"""Emotion: Relieved"""

eighth = final_dts[["Q6", "Q25h"]]
dfh_technical = pd.DataFrame(eighth)
dfh_technical.info()

technical_relieved = dfh_technical.loc[(dfh_technical['Q6'] == 4) & (dfh_technical['Q25h'] == 1)]
data_relieved = technical_relieved.drop('Q6', axis = 1)
Data_relieved = data_relieved.value_counts()
technical_data_relieved = Data_relieved.tolist()

technical1_relieved = dfh_technical.loc[(dfh_technical['Q6'] == 4) & (dfh_technical['Q25h'] == 2)]
data1_relieved = technical1_relieved.drop('Q6', axis = 1)
Data1_relieved = data1_relieved.value_counts()
technical_data1_relieved = Data1_relieved.tolist()

technical2_relieved = dfh_technical.loc[(dfh_technical['Q6'] == 4) & (dfh_technical['Q25h'] == 3)]
data2_relieved = technical2_relieved.drop('Q6', axis = 1)
Data2_relieved = data2_relieved.value_counts()
technical_data2_relieved = Data2_relieved.tolist()

technical3_relieved = dfh_technical.loc[(dfh_technical['Q6'] == 4) & (dfh_technical['Q25h'] == 4)]
data3_relieved = technical3_relieved.drop('Q6', axis = 1)
Data3_relieved = data3_relieved.value_counts()
technical_data3_relieved = Data3_relieved.tolist()

technical4_relieved = dfh_technical.loc[(dfh_technical['Q6'] == 4) & (dfh_technical['Q25h'] == 5)]
data4_relieved = technical4_relieved.drop('Q6', axis = 1)
Data4_relieved = data4_relieved.value_counts()
technical_data4_relieved = Data4_relieved.tolist()

"""Emotion: Hopless"""

ninth = final_dts[["Q6", "Q25i"]]
dfi_technical = pd.DataFrame(ninth)
dfi_technical.info()

technical_hopeless = dfi_technical.loc[(dfi_technical['Q6'] == 4) & (dfi_technical['Q25i'] == 1)]
data_hopeless = technical_hopeless.drop('Q6', axis = 1)
Data_hopeless = data_hopeless.value_counts()
technical_data_hopeless = Data_hopeless.tolist()

technical1_hopeless = dfi_technical.loc[(dfi_technical['Q6'] == 4) & (dfi_technical['Q25i'] == 2)]
data1_hopeless = technical1_hopeless.drop('Q6', axis = 1)
Data1_hopeless = data1_hopeless.value_counts()
technical_data1_hopeless = Data1_hopeless.tolist()

technical2_hopeless = dfi_technical.loc[(dfi_technical['Q6'] == 4) & (dfi_technical['Q25i'] == 3)]
data2_hopeless = technical2_hopeless.drop('Q6', axis = 1)
Data2_hopeless = data2_hopeless.value_counts()
technical_data2_hopeless = Data2_hopeless.tolist()

technical3_hopeless = dfi_technical.loc[(dfi_technical['Q6'] == 4) & (dfi_technical['Q25i'] == 4)]
data3_hopeless = technical3_hopeless.drop('Q6', axis = 1)
Data3_hopeless = data3_hopeless.value_counts()
technical_data3_hopeless = Data3_hopeless.tolist()

technical4_hopeless = dfi_technical.loc[(dfi_technical['Q6'] == 4) & (dfi_technical['Q25i'] == 5)]
data4_hopeless = technical4_hopeless.drop('Q6', axis = 1)
Data4_hopeless = data4_hopeless.value_counts()
technical_data4_hopeless = Data4_hopeless.tolist()

"""Emotion: Bored"""

tenth = final_dts[["Q6", "Q25j"]]
dfj_technical = pd.DataFrame(tenth)
dfj_technical.info()

technical_bored = dfj_technical.loc[(dfj_technical['Q6'] == 4) & (dfj_technical['Q25j'] == 1)]
data_bored = technical_bored.drop('Q6', axis = 1)
Data_bored = data_bored.value_counts()
technical_data_bored = Data_bored.tolist()

technical1_bored = dfj_technical.loc[(dfj_technical['Q6'] == 4) & (dfj_technical['Q25j'] == 2)]
data1_bored = technical1_bored.drop('Q6', axis = 1)
Data1_bored = data1_bored.value_counts()
technical_data1_bored = Data1_bored.tolist()

technical2_bored = dfj_technical.loc[(dfj_technical['Q6'] == 4) & (dfj_technical['Q25j'] == 3)]
data2_bored = technical2_bored.drop('Q6', axis = 1)
Data2_bored = data2_bored.value_counts()
technical_data2_bored = Data2_bored.tolist()

technical3_bored = dfj_technical.loc[(dfj_technical['Q6'] == 4) & (dfj_technical['Q25j'] == 4)]
data3_bored = technical3_bored.drop('Q6', axis = 1)
Data3_bored = data3_bored.value_counts()
technical_data3_bored = Data3_bored.tolist()

technical4_bored = dfj_technical.loc[(dfj_technical['Q6'] == 4) & (dfj_technical['Q25j'] == 5)]
data4_bored = technical4_bored.drop('Q6', axis = 1)
Data4_bored = data4_bored.value_counts()
technical_data4_bored = Data4_bored.tolist()

"""Emotions Rate Felt by Arts and Humanities Students"""

fig, ax = plt.subplots(figsize=(19, 9))
labels = ["Never", "Rarely", "Sometimes", "Often", "Always"]
category_labels = ["Joyful", "Hopeful", "Proud", "Frustrated", "Angry", "Anxious", "Ashamed", "Relieved", "Hopeless", "Bored"]

art_field_never = art_data_joyful + art_data_hopeful + art_data_proud + art_data_frustrated + art_data_angry + art_data_anxious + art_data_ashamed + art_data_relieved + art_data_hopeless + art_data_bored
art_field_rarely = art_data1_joyful + art_data1_hopeful + art_data1_proud + art_data1_frustrated + art_data1_angry + art_data1_anxious + art_data1_ashamed + art_data1_relieved + art_data1_hopeless + art_data1_bored
art_field_sometimes = art_data2_joyful + art_data2_hopeful + art_data2_proud + art_data2_frustrated + art_data2_angry + art_data2_anxious + art_data2_ashamed + art_data2_relieved + art_data2_hopeless + art_data2_bored
art_field_often = art_data3_joyful + art_data3_hopeful + art_data3_proud + art_data3_frustrated + art_data3_angry + art_data3_anxious + art_data3_ashamed + art_data3_relieved + art_data3_hopeless + art_data3_bored
art_field_always = art_data4_joyful + art_data4_hopeful + art_data4_proud + art_data4_frustrated + art_data4_angry + art_data4_anxious + art_data4_ashamed + art_data4_relieved + art_data4_hopeless + art_data4_bored

art_bottom1 = art_field_never
art_bottom2 = [a+b for a,b in zip(art_field_never, art_field_rarely)]
art_bottom3 = [a+b+c for a,b,c in zip(art_field_never, art_field_rarely, art_field_sometimes)]
art_bottom4 = [a+b+c+d for a,b,c,d in zip(art_field_never, art_field_rarely, art_field_sometimes, art_field_often)]

p1 = ax.barh(category_labels, art_field_never, color = '#F28B50')
p2 = ax.barh(category_labels, art_field_rarely, left = art_bottom1, color = '#F2C0A2')
p3 = ax.barh(category_labels, art_field_sometimes, left = art_bottom2, color = '#ABABAB')
p4 = ax.barh(category_labels, art_field_often, left = art_bottom3, color = '#A2D4F2')
p5 = ax.barh(category_labels, art_field_always, left = art_bottom4, color = '#3D9DD9')

ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(True)
ax.spines['bottom'].set_visible(False)

ax.yaxis.grid(False)
ax.xaxis.grid(True, which='major', color='#BFBFBF')
ax.set_axisbelow(True)

plt.ylabel("Emotions", fontsize=12)
plt.xlabel("Responses", fontsize=12)
plt.title("Emotions Rate felt by Arts and Humanities Students", fontsize = 20, fontweight='bold')
ax.legend(labels, bbox_to_anchor=(0.5,-0.14), loc='lower center', ncol=5, fontsize = 13)
plt.show()

"""Emotions Rate Felt by Social Science Students"""

fig, ax = plt.subplots(figsize=(19, 9))
labels = ["Never", "Rarely", "Sometimes", "Often", "Always"]
category_labels = ["Joyful", "Hopeful", "Proud", "Frustrated", "Angry", "Anxious", "Ashamed", "Relieved", "Hopeless", "Bored"]

social_field_never = social_data_joyful + social_data_hopeful + social_data_proud + social_data_frustrated + social_data_angry + social_data_anxious + social_data_ashamed + social_data_relieved + social_data_hopeless + social_data_bored
social_field_rarely = social_data1_joyful + social_data1_hopeful + social_data1_proud + social_data1_frustrated + social_data1_angry + social_data1_anxious + social_data1_ashamed + social_data1_relieved + social_data1_hopeless + social_data1_bored
social_field_sometimes = social_data2_joyful + social_data2_hopeful + social_data2_proud + social_data2_frustrated + social_data2_angry + social_data2_anxious + social_data2_ashamed + social_data2_relieved + social_data2_hopeless + social_data2_bored
social_field_often = social_data3_joyful + social_data3_hopeful + social_data3_proud + social_data3_frustrated + social_data3_angry + social_data3_anxious + social_data3_ashamed + social_data3_relieved + social_data3_hopeless + social_data3_bored
social_field_always = social_data4_joyful + social_data4_hopeful + social_data4_proud + social_data4_frustrated + social_data4_angry + social_data4_anxious + social_data4_ashamed + social_data4_relieved + social_data4_hopeless + social_data4_bored

social_bottom1 = social_field_never
social_bottom2 = [a+b for a,b in zip(social_field_never, social_field_rarely)]
social_bottom3 = [a+b+c for a,b,c in zip(social_field_never, social_field_rarely, social_field_sometimes)]
social_bottom4 = [a+b+c+d for a,b,c,d in zip(social_field_never, social_field_rarely, social_field_sometimes, social_field_often)]

p1 = ax.barh(category_labels, social_field_never, color = '#F28B50')
p2 = ax.barh(category_labels, social_field_rarely, left = social_bottom1, color = '#F2C0A2')
p3 = ax.barh(category_labels, social_field_sometimes, left = social_bottom2, color = '#ABABAB')
p4 = ax.barh(category_labels, social_field_often, left = social_bottom3, color = '#A2D4F2')
p5 = ax.barh(category_labels, social_field_always, left = social_bottom4, color = '#3D9DD9')

ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(True)
ax.spines['bottom'].set_visible(False)

ax.yaxis.grid(False)
ax.xaxis.grid(True, which='major', color='#BFBFBF')
ax.set_axisbelow(True)

plt.ylabel("Emotions", fontsize=12)
plt.xlabel("Responses", fontsize=12)
plt.title("Emotions Rate felt by Social Science Students", fontsize = 20, fontweight='bold')
ax.legend(labels, bbox_to_anchor=(0.5,-0.14), loc='lower center', ncol=5, fontsize = 13)
plt.show()

"""Emotions Rate Felt by Natural and Life Science Students"""

fig, ax = plt.subplots(figsize=(19, 9))
labels = ["Never", "Rarely", "Sometimes", "Often", "Always"]
category_labels = ["Joyful", "Hopeful", "Proud", "Frustrated", "Angry", "Anxious", "Ashamed", "Relieved", "Hopeless", "Bored"]

natural_field_never = natural_data_joyful + natural_data_hopeful + natural_data_proud + natural_data_frustrated + natural_data_angry + natural_data_anxious + natural_data_ashamed + natural_data_relieved + natural_data_hopeless + natural_data_bored
natural_field_rarely = natural_data1_joyful + natural_data1_hopeful + natural_data1_proud + natural_data1_frustrated + natural_data1_angry + natural_data1_anxious + natural_data1_ashamed + natural_data1_relieved + natural_data1_hopeless + natural_data1_bored
natural_field_sometimes = natural_data2_joyful + natural_data2_hopeful + natural_data2_proud + natural_data2_frustrated + natural_data2_angry + natural_data2_anxious + natural_data2_ashamed + natural_data2_relieved + natural_data2_hopeless + natural_data2_bored
natural_field_often = natural_data3_joyful + natural_data3_hopeful + natural_data3_proud + natural_data3_frustrated + natural_data3_angry + natural_data3_anxious + natural_data3_ashamed + natural_data3_relieved + natural_data3_hopeless + natural_data3_bored
natural_field_always = natural_data4_joyful + natural_data4_hopeful + natural_data4_proud + natural_data4_frustrated + natural_data4_angry + natural_data4_anxious + natural_data4_ashamed + natural_data4_relieved + natural_data4_hopeless + natural_data4_bored

natural_bottom1 = natural_field_never
natural_bottom2 = [a+b for a,b in zip(natural_field_never, natural_field_rarely)]
natural_bottom3 = [a+b+c for a,b,c in zip(natural_field_never, natural_field_rarely, natural_field_sometimes)]
natural_bottom4 = [a+b+c+d for a,b,c,d in zip(natural_field_never, natural_field_rarely, natural_field_sometimes, natural_field_often)]

p1 = ax.barh(category_labels, natural_field_never, color = '#F28B50')
p2 = ax.barh(category_labels, natural_field_rarely, left = natural_bottom1, color = '#F2C0A2')
p3 = ax.barh(category_labels, natural_field_sometimes, left = natural_bottom2, color = '#ABABAB')
p4 = ax.barh(category_labels, natural_field_often, left = natural_bottom3, color = '#A2D4F2')
p5 = ax.barh(category_labels, natural_field_always, left = natural_bottom4, color = '#3D9DD9')

ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(True)
ax.spines['bottom'].set_visible(False)

ax.yaxis.grid(False)
ax.xaxis.grid(True, which='major', color='#BFBFBF')
ax.set_axisbelow(True)

plt.ylabel("Emotions", fontsize=12)
plt.xlabel("Responses", fontsize=12)
plt.title("Emotions Rate felt by Natural and Life Science Students", fontsize = 20, fontweight='bold')
ax.legend(labels, bbox_to_anchor=(0.5,-0.14), loc='lower center', ncol=5, fontsize = 13)
plt.show()

"""Emotions Rate Felt by Technical Students"""

fig, ax = plt.subplots(figsize=(19, 9))
labels = ["Never", "Rarely", "Sometimes", "Often", "Always"]
category_labels = ["Joyful", "Hopeful", "Proud", "Frustrated", "Angry", "Anxious", "Ashamed", "Relieved", "Hopeless", "Bored"]

technical_field_never = technical_data_joyful + technical_data_hopeful + technical_data_proud + technical_data_frustrated + technical_data_angry + technical_data_anxious + technical_data_ashamed + technical_data_relieved + technical_data_hopeless + technical_data_bored
technical_field_rarely = technical_data1_joyful + technical_data1_hopeful + technical_data1_proud + technical_data1_frustrated + technical_data1_angry + technical_data1_anxious + technical_data1_ashamed + technical_data1_relieved + technical_data1_hopeless + technical_data1_bored
technical_field_sometimes = technical_data2_joyful + technical_data2_hopeful + technical_data2_proud + technical_data2_frustrated + technical_data2_angry + technical_data2_anxious + technical_data2_ashamed + technical_data2_relieved + technical_data2_hopeless + technical_data2_bored
technical_field_often = technical_data3_joyful + technical_data3_hopeful + technical_data3_proud + technical_data3_frustrated + technical_data3_angry + technical_data3_anxious + technical_data3_ashamed + technical_data3_relieved + technical_data3_hopeless + technical_data3_bored
technical_field_always = technical_data4_joyful + technical_data4_hopeful + technical_data4_proud + technical_data4_frustrated + technical_data4_angry + technical_data4_anxious + technical_data4_ashamed + technical_data4_relieved + technical_data4_hopeless + technical_data4_bored

technical_bottom1 = technical_field_never
technical_bottom2 = [a+b for a,b in zip(technical_field_never, technical_field_rarely)]
technical_bottom3 = [a+b+c for a,b,c in zip(technical_field_never, technical_field_rarely, technical_field_sometimes)]
technical_bottom4 = [a+b+c+d for a,b,c,d in zip(technical_field_never, technical_field_rarely, technical_field_sometimes, technical_field_often)]

p1 = ax.barh(category_labels, technical_field_never, color = '#F28B50')
p2 = ax.barh(category_labels, technical_field_rarely, left = technical_bottom1, color = '#F2C0A2')
p3 = ax.barh(category_labels, technical_field_sometimes, left = technical_bottom2, color = '#ABABAB')
p4 = ax.barh(category_labels, technical_field_often, left = technical_bottom3, color = '#A2D4F2')
p5 = ax.barh(category_labels, technical_field_always, left = technical_bottom4, color = '#3D9DD9')

ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(True)
ax.spines['bottom'].set_visible(False)

ax.yaxis.grid(False)
ax.xaxis.grid(True, which='major', color='#BFBFBF')
ax.set_axisbelow(True)

plt.ylabel("Emotions", fontsize=12)
plt.xlabel("Responses", fontsize=12)
plt.title("Emotions Rate felt by Technical Students", fontsize = 20, fontweight='bold')
ax.legend(labels, bbox_to_anchor=(0.5,-0.14), loc='lower center', ncol=5, fontsize = 13)
plt.show()

"""#Q7 and Q25(a, b, c, d, e, f, g, h, i, and j)- rate of emotions felt based on the age bracket

Age grouping:  
18 - 19 years old  
20 - 21 years old  
22 - 24 years old  
25 years old and older

Converting age into int dtype
"""

final_dts['Q7'].unique()

final_dts['Q7'].dtype

final_dts['Q7'] = final_dts['Q7'].astype('int64')
final_dts['Q7'].dtype

final_dts['Q7'].unique()

"""Dataframe of Q7 and Q25

"""

q7_q25_df = final_dts[['Q7', 'Q25a', 'Q25b', 'Q25c', 'Q25d', 'Q25e', 'Q25f', 'Q25g', 'Q25h', 'Q25i', 'Q25j']].sort_values(by='Q7')
q7_q25_df.set_index(['Q7'], inplace=True)
q7_q25_df

#breaking down dataframe based on age groups
age_18_to_19_df = q7_q25_df.loc[18:19]
age_20_to_21_df = q7_q25_df.loc[20:21]
age_22_to_24_df = q7_q25_df.loc[22:24]
age_25_older_df = q7_q25_df.loc[25:]

age_25_older_df

"""Emotion rate based within 18 to 19 age

Preparing variables to be used in plotting

Computing the composition of each Q25 emotion based on 18 and 19 (for testing)
"""

q25 = ['Q25a', 'Q25b', 'Q25c', 'Q25d', 'Q25e', 'Q25f', 'Q25g', 'Q25h', 'Q25i', 'Q25j']
scale_schema = {
    '1.0': 'Never',
    '2.0': 'Rarely',
    '3.0': 'Sometimes',
    '4.0': 'Often',
    '5.0': 'Always'
}
q25_reponses_dict = {
    'Never': [],
    'Rarely': [],
    'Sometimes': [],
    'Often': [],
    'Always': [],
}

index = age_22_to_24_df[q25[0]].value_counts(normalize=True).index
values = age_22_to_24_df[q25[0]].value_counts(normalize=True).values
portions = [round(x*100,2) for x in values] #multiply by 100 each values

portions

for q in q25:
  index = age_22_to_24_df[q].value_counts(normalize=True).index.astype(str)
  values = age_22_to_24_df[q].value_counts(normalize=True).values
  portions = [round(x*100, 2) for x in values] #multiply by 100 each values
  for key, val in zip(index, portions):
    q25_reponses_dict[scale_schema[key]].append(val)

index[0]

summary_df = pd.DataFrame(q25_reponses_dict, index=q25)
summary_df

"""Likert scale and labels"""

q25_scale_dict = {
              '1.0': "Never", 
              '2.0': "Rarely", 
              '3.0': "Sometimes", 
              '4.0': "Often", 
              '5.0':"Always"
            }
q23_scale_dict = {
              '1.0': "Not at all", 
              '2.0': "Two or three times a month", 
              '3.0': "Once a week", 
              '4.0': "Several times a week", 
              '5.0': "Once a day", 
              '6.0': "Several times a day"
            }

q25_scale_list = ["Never", "Rarely", "Sometimes", "Often", "Always"]
q23_scale_list = ["Not at all", "Two or three times a month", "Once a week", "Several times a week", "Once a day", "Several times a day"]

q25_labels = ['Joyful', 'Hopeful', 'Proud', 'Frustrated', 'Angry', 'Anxious', 'Ashamed', 'Relieved', 'Hopeless', 'Bored']
q23_labels = ['Close family member', 'More distant family member', 'Close friend', 'Someone I live with (e.g. roommate)', 'Neighbours', 'Colleague from my course', 'Lecturer', 'Administrative staff', 'Voluntary organizations', 'Social networks']

"""Functions"""

#for aggregating the q25
#returns new dataframe of aggregated q25 responses 
def aggregate_q25(df, **likert_scale):
  q25_responses_dict = {}
  df_columns = list(df.columns)
  #print(df_columns)
  #populates the dict with likert scale properties
  for scale in likert_scale.values():
    q25_responses_dict[scale] = []
    #print(q25_responses_dict)

  #accumulates each percentage of likert scale per question/emotion
  for col in df_columns:
    #print(col)
    index = df[col].value_counts(normalize=True).index.astype('str') #contains index from the result of value_counts
    values = df[col].value_counts(normalize=True).values #contains value from the result of value_counts
    portions = [round(x*100, 2) for x in values] #multiply by 100 each values
    #print(df[col].value_counts(normalize=True))
    #print(index)
    #print(portions)

    #populates each scale
    for key, val in zip(index, portions): 
      q25_responses_dict[likert_scale[key]].append(val)

  #print(q25_responses_dict)
  
  return pd.DataFrame(q25_responses_dict, index=df_columns)

def diverging_stacked_plotter(ax, df, likert_scale, labels, **dict_params):
  #color_palettes
  #blue to green
  q25_color_palettes = ['#1261a0', '#58cced', '#e0e0e0', '#5ced73',  '#00c04b'] 
  q23_color_palletes = ['#03a9f4', '#4fc3f7', '#9addfb', '#c9f1c9', '#a0e7a0', '#77dd77']
  color_in_use = q25_color_palettes if 'Never' in likert_scale else q23_color_palletes


  #cumulative sum of df
  cumsum_df = df.cumsum(axis=1)
  offsets = np.add(cumsum_df['Rarely'], df['Sometimes']/2) if 'Never' in likert_scale else cumsum_df["Once a week"]
  ylabel = 'Emotions' if 'Never' in likert_scale else 'People to communicate with through online'

  #formula of left value of each bar 
  #left = cumsum_of_portion - portion - offset

  for index, scale in enumerate(likert_scale):
    portion = df[scale]
    starts = cumsum_df[scale] - portion - offsets
    stacks = ax.barh(labels, portion, left=starts, label=scale, color=color_in_use[index])
    
  #zero reference line
  ax.axvline(0, linestyle='--', color='black', alpha=.25)

  #only in recent versions
  #ax.bar_label(p1, label_type='center')
  #ax.bar_label(p2, label_type='center')
  #ax.bar_label(p3, label_type='center')
  #ax.bar_label(p4, label_type='center')
  #ax.bar_label(p5, label_type='center')

  ax.spines['right'].set_visible(False)
  ax.spines['top'].set_visible(False)
  ax.spines['left'].set_visible(False)
  ax.spines['bottom'].set_visible(True)

  ax.yaxis.grid(False)
  ax.xaxis.grid(True, which='major', color='grey', linestyle='dotted')
  ax.set_axisbelow(True)

  #x-axis
  ax.set_xlim(-100, 100)
  ax.set_xticks(np.arange(-100, 101, 10))
  ax.xaxis.set_major_formatter(tick.FuncFormatter(lambda x, pos: str(abs(int(x)))))

  
  ax.set_ylabel('Emotions', fontsize=13)
  ax.set_xlabel('Rate', fontsize=13)

  ax.set_ylabel(ylabel)

  ax.set_title(dict_params['title'], loc='center', fontsize=18, fontweight='bold')
  ax.legend(bbox_to_anchor=(0.5,-0.25), loc='lower center', ncol=6, fontsize=12)

#for stacked column plotting (only works in q25)
def stacked_bar_plotter(ax, df, **dict_params):
  b_sometimes = list(np.add(df['Never'], df['Rarely']))
  b_often = list(np.add(b_sometimes, df['Sometimes']))
  b_always = list(np.add(b_often, df['Often']))

  p1 = ax.barh(labels, df['Never'], dict_params['width'], label="Never")
  p2 = ax.barh(labels, df['Rarely'], dict_params['width'], left=df['Never'], label="Rarely")
  p3 = ax.barh(labels, df['Sometimes'], dict_params['width'], left=b_sometimes, label="Sometimes")
  p4 = ax.barh(labels, df['Often'], dict_params['width'], left=b_often, label="Often")
  p5 = ax.barh(labels, df['Always'], dict_params['width'], left=b_always, label="Always")

  #only in recent versions
  #ax.bar_label(p1, label_type='center')
  #ax.bar_label(p2, label_type='center')
  #ax.bar_label(p3, label_type='center')
  #ax.bar_label(p4, label_type='center')
  #ax.bar_label(p5, label_type='center')

  ax.spines['right'].set_visible(False)
  ax.spines['top'].set_visible(False)

  ax.set_xlabel('Rate')
  ax.set_ylabel('Emotions')
  ax.set_title(dict_params['title'])
  ax.legend()

"""18 to 19 Years Old Emotion Rate

"""

summary_18_19_df = aggregate_q25(age_18_to_19_df, **q25_scale_dict)
summary_18_19_df

params_dict = {
    'title': 'Rate of Emotions felt by 18 and 19 Years Old College Students',
}

fig, ax = plt.subplots()
fig.set_size_inches(16, 5, forward=True)
diverging_stacked_plotter(ax, summary_18_19_df, q25_scale_list, q25_labels, **params_dict)

"""20-21 Years Old Emotion Rate"""

summary_20_21_df = aggregate_q25(age_20_to_21_df, **q25_scale_dict)
summary_20_21_df

params_dict = {
    'title': 'Rate of Emotions felt by 20 and 21 Years Old College Students',
}

fig, ax = plt.subplots()
fig.set_size_inches(16, 5, forward=True)
diverging_stacked_plotter(ax, summary_20_21_df, q25_scale_list, q25_labels, **params_dict)

"""22-24 Years Old Emotion Rate"""

summary_22_24_df = aggregate_q25(age_22_to_24_df, **q25_scale_dict)
summary_22_24_df

params_dict = {
    'title': 'Rate of Emotions felt by 22 to 24 Years Old College Students',
}

fig, ax = plt.subplots()
fig.set_size_inches(16, 5, forward=True)
diverging_stacked_plotter(ax, summary_22_24_df, q25_scale_list, q25_labels, **params_dict)

"""25 Years Old and Older Emotion Rate"""

summary_25_older_df = aggregate_q25(age_25_older_df, **q25_scale_dict)
summary_25_older_df

params_dict = {
    'title': 'Rate of Emotions felt by 25 Years Old and Older College Students',
}

fig, ax = plt.subplots()
fig.set_size_inches(16, 5, forward=True)
diverging_stacked_plotter(ax, summary_25_older_df, q25_scale_list, q25_labels, **params_dict)

"""# Q17- workload rate of students during online setup compared to on-site classes"""

Q17_workload = final_dts

Q17_workload_rate = Q17_workload ['Q17']
Q17_data = pd.DataFrame(Q17_workload_rate)
Q17_result = Q17_data.value_counts(sort=False)
print(Q17_result)

# setting the workload rate at x axis
workload_rate=['Significantly smaller', 'Smaller', 'The same', 'Larger', 'Significantly larger']

# giving the values against each value at y axis
workload_result=[91,156,197,1017,139]

fig, ax = plt.subplots(figsize=(13,7))
plt.bar(workload_rate, workload_result, color=['#77C2FE', '#249CFF', '#1578CF', '#0A579E', '#003870'], width=0.9)

plt.ylim(0, 1200)
plt.yticks(np.arange(0, 1201, 200))

ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.spines['bottom'].set_visible(True)

ax.yaxis.grid(True, which='major', color='grey', linestyle='dotted')
ax.xaxis.grid(False)
ax.set_axisbelow(True)

# setting labels
plt.xlabel("Rate", fontsize=12)
plt.ylabel("Responses", fontsize=12)  
plt.title("Students' Workload Rate in Online Learning Setup", loc='center', fontsize=18, fontweight='bold')
plt.show()

"""# Q20(a, b, c, d, e, and f)- performance rate of students"""

#identifying rate values of the perfomance of the students
Q20_performance = final_dts

Q20a = Q20_performance ['Q20a']
Q20a_data = pd.DataFrame(Q20a)
Q20a_result = Q20a_data.value_counts(sort=False)
print(Q20a_result)

Q20b = Q20_performance ['Q20b']
Q20b_data = pd.DataFrame(Q20b)
Q20b_result = Q20b_data.value_counts(sort=False)
print(Q20b_result)

Q20c = Q20_performance ['Q20c']
Q20c_data = pd.DataFrame(Q20c)
Q20c_result = Q20c_data.value_counts(sort=False)
print(Q20c_result)

Q20d = Q20_performance ['Q20d']
Q20d_data = pd.DataFrame(Q20d)
Q20d_result = Q20d_data.value_counts(sort=False)
print(Q20d_result)

Q20e = Q20_performance ['Q20e']
Q20e_data = pd.DataFrame(Q20e)
Q20e_result = Q20e_data.value_counts(sort=False)
print(Q20e_result)

Q20f = Q20_performance ['Q20f']
Q20f_data = pd.DataFrame(Q20f)
Q20f_result = Q20f_data.value_counts(sort=False)
print(Q20f_result)

performance_rate = ['Strongly Disagree', 'Disagree', 'Natural', 'Agree', 'Strongly Agree']
perf_statement_results = {
    'It is more difficult for me to focus during online teaching in comparison to on-site teaching.': [55,65,135,1135,210],
    'My performance as a student has improved since on-site classes were canceled.': [111,212,1134,114,29],
    'My performance as a student has worsened since on-site classes were canceled.': [46,128,1131,194,101],
    'I have adapted well to the new teaching and learning experience.': [59,102,1155,216,68],
    'I can master the skills taught in class this year even if on-site classes were canceled.': [57,162,1183,166,32],
    'I can figure out how to do the most difficult classwork since on-site classes were canceled.': [54,129,1201,180,36],
}

def questionnaire_prs(perf_statement_results, performance_rate):
    labels = list(perf_statement_results.keys())
    data = np.array(list(perf_statement_results.values()))
    data_cum = data.cumsum(axis=1)
    middle_index = data.shape[1]//2
    offsets = data[:, range(middle_index)].sum(axis=1) + data[:, middle_index]/2

    # Color Mapping
    category_colors = plt.get_cmap('coolwarm_r')(np.linspace(0.19, 0.9, data.shape[1]))
    
    fig, ax = plt.subplots(figsize=(11.5,5))
    
    # Plot Bars
    for i, (colname, color) in enumerate(zip(performance_rate, category_colors)):
        widths = data[:, i]
        starts = data_cum[:, i] - widths - offsets
        rects = ax.barh(labels, widths, left=starts, height=0.8,
                        label=colname, color=color)
    
    # Add Zero Reference Line
    ax.axvline(0, linestyle='--', color='black', alpha=0.5)
    
    # X Axis
    ax.set_xlim(-1500, 1500)
    ax.set_xticks(np.arange(-1500, 1501, 300))
    
    # Y Axis
    ax.invert_yaxis()
    
    # Remove spines
    ax.spines['right'].set_visible(False)
    ax.spines['top'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(True)

    ax.yaxis.grid(False)
    ax.xaxis.grid(True, which='major', color='grey', linestyle='dotted')
    ax.set_axisbelow(True)
    
    # Legend
    ax.legend(ncol=len(performance_rate), bbox_to_anchor=(0.5,-0.28), loc='lower center', fontsize=12)
    
    #Title and xy-labels
    ax.set_title('Performance Rate of Students', loc='center', fontsize=18, fontweight='bold')
    ax.set_ylabel('Statements', fontsize=14)
    ax.set_xlabel('Responses', fontsize=14)

    # Set Background Color
    fig.set_facecolor('#FFFFFF')

    return fig, ax

fig, ax = questionnaire_prs(perf_statement_results, performance_rate)
plt.show()

"""# Q21(c and i)- access rate on computer and good internet connection

"""

Q21c_df = final_dts["Q21c"]
df_Q21c = pd.DataFrame(Q21c_df)
df_Q21c.info()

Q21c_data1 = df_Q21c.loc[lambda df_Q21c: df_Q21c['Q21c'] == 1]
Q21c_count1 = Q21c_data1.value_counts()
Q21c_never = Q21c_count1.tolist()

Q21c_data2 = df_Q21c.loc[lambda df_Q21c: df_Q21c['Q21c'] == 2]
Q21c_count2 = Q21c_data2.value_counts()
Q21c_rarely = Q21c_count2.tolist()

Q21c_data3 = df_Q21c.loc[lambda df_Q21c: df_Q21c['Q21c'] == 3]
Q21c_count3 = Q21c_data3.value_counts()
Q21c_sometimes = Q21c_count3.tolist()

Q21c_data4 = df_Q21c.loc[lambda df_Q21c: df_Q21c['Q21c'] == 4]
Q21c_count4 = Q21c_data4.value_counts()
Q21c_often = Q21c_count4.tolist()

Q21c_data5 = df_Q21c.loc[lambda df_Q21c: df_Q21c['Q21c'] == 5]
Q21c_count5 = Q21c_data5.value_counts()
Q21c_always = Q21c_count5.tolist()

Q21c_final = Q21c_never + Q21c_rarely + Q21c_sometimes + Q21c_often + Q21c_always
print(Q21c_final)

fig, ax = plt.subplots(figsize=(13,7))
plt.ylim(0, 1400)
plt.yticks(np.arange(0, 1401, 200))

labels = ["Never", "Rarely", "Sometimes", "Often", "Always"]

ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.spines['bottom'].set_visible(True)

ax.yaxis.grid(True, which='major', color='grey', linestyle='dotted')
ax.xaxis.grid(False)
ax.set_axisbelow(True)

Q21c = ax.bar(labels, Q21c_final, color = ['#FFB380', '#FFA466', '#FF954D', '#FF8533', '#FF7619'], width=0.9)

plt.xlabel("Rate", fontsize=12)
plt.ylabel("Responses", fontsize=12)  
plt.title("Students' Access Rate on Computer", fontsize=18, fontweight='bold')
plt.show()

Q21i_df = final_dts["Q21i"]
df_Q21i = pd.DataFrame(Q21i_df)
df_Q21i.info()

Q21i_data1 = df_Q21i.loc[lambda df_Q21i: df_Q21i['Q21i'] == 1]
Q21i_count1 = Q21i_data1.value_counts()
Q21i_never = Q21i_count1.tolist()

Q21i_data2 = df_Q21i.loc[lambda df_Q21i: df_Q21i['Q21i'] == 2]
Q21i_count2 = Q21i_data2.value_counts()
Q21i_rarely = Q21i_count2.tolist()

Q21i_data3 = df_Q21i.loc[lambda df_Q21i: df_Q21i['Q21i'] == 3]
Q21i_count3 = Q21i_data3.value_counts()
Q21i_sometimes = Q21i_count3.tolist()

Q21i_data4 = df_Q21i.loc[lambda df_Q21i: df_Q21i['Q21i'] == 4]
Q21i_count4 = Q21i_data4.value_counts()
Q21i_often = Q21i_count4.tolist()

Q21i_data5 = df_Q21i.loc[lambda df_Q21i: df_Q21i['Q21i'] == 5]
Q21i_count5 = Q21i_data5.value_counts()
Q21i_always = Q21i_count5.tolist()

Q21i_final = Q21i_never + Q21i_rarely + Q21i_sometimes + Q21i_often + Q21i_always
print(Q21i_final)

fig, ax = plt.subplots(figsize=(13,7))
plt.ylim(0, 1200)
plt.yticks(np.arange(0, 1201, 200))

labels = ["Never", "Rarely", "Sometimes", "Often", "Always"]

ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.spines['bottom'].set_visible(True)

ax.yaxis.grid(True, which='major', color='grey', linestyle='dotted')
ax.xaxis.grid(False)
ax.set_axisbelow(True)

Q21i = ax.bar(labels, Q21i_final, color = ['#FF998B', '#FF7E72', '#E36359', '#C44841', '#A62C2B'], width=0.9)

plt.xlabel("Rate", fontsize=12)
plt.ylabel("Responses", fontsize=12)  
plt.title("Students' Access Rate on Good Internet Connection", fontsize=18, fontweight='bold')
plt.show()

"""# Q22(a and b)- rate about browsing online information and sharing digital content"""

Q22_online_performance = final_dts

Q22a = Q22_online_performance ['Q22a']
Q22a_data = pd.DataFrame(Q22a)
Q22a_result = Q22a_data.value_counts(sort=False)
print(Q22a_result)

Q22b = Q22_online_performance ['Q22b']
Q22b_data = pd.DataFrame(Q22b)
Q22b_result = Q22b_data.value_counts(sort=False)
print(Q22b_result)

browse_share_performance_rate = ['Strongly Disagree', 'Disagree', 'Natural', 'Agree', 'Strongly Agree']
br_sh_statement_results = {
    'Browsing online information.': [31,53,173,1179,164],
    'Sharing digital content.': [27,56,203,1170,144],
}

def questionnaire_br_sh(br_sh_statement_results, browse_share_performance_rate):
    labels = list(br_sh_statement_results.keys())
    data = np.array(list(br_sh_statement_results.values()))
    data_cum = data.cumsum(axis=1)
    middle_index = data.shape[1]//2
    offsets = data[:, range(middle_index)].sum(axis=1) + data[:, middle_index]/2

    # Color Mapping
    category_colors = plt.get_cmap('coolwarm_r')(np.linspace(0.19, 0.9, data.shape[1]))
    
    fig, ax = plt.subplots(figsize=(13,1.5))
    
    # Plot Bars
    for i, (colname, color) in enumerate(zip(browse_share_performance_rate, category_colors)):
        widths = data[:, i]
        starts = data_cum[:, i] - widths - offsets
        rects = ax.barh(labels, widths, left=starts, height=0.7,
                        label=colname, color=color)
    
    # Add Zero Reference Line
    ax.axvline(0, linestyle='--', color='black', alpha=0.5)
    
    # X Axis
    ax.set_xlim(-1500, 1500)
    ax.set_xticks(np.arange(-1500, 1501, 300))
    
    # Y Axis
    ax.invert_yaxis()
    
    # Remove spines
    ax.spines['right'].set_visible(False)
    ax.spines['top'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(True)

    ax.yaxis.grid(False)
    ax.xaxis.grid(True, which='major', color='grey', linestyle='dotted')
    ax.set_axisbelow(True)
    
    # Legend
    ax.legend(ncol=len(browse_share_performance_rate), bbox_to_anchor=(0.5,-0.9), loc='lower center', fontsize=11)
    
    #Title and xy-labels
    ax.set_title('Performance Rate of Students', loc='center', fontsize=18, fontweight='bold')
    ax.set_ylabel('Statements', fontsize=11)
    ax.set_xlabel('Responses', fontsize=11)

    # Set Background Color
    fig.set_facecolor('#FFFFFF')

    return fig, ax

fig, ax = questionnaire_br_sh(br_sh_statement_results, browse_share_performance_rate)
plt.show()

"""#Q23- communication with other people rate (social life)

Dataframe of Q23
"""

q23_df = final_dts[['Q23a', 'Q23b', 'Q23c', 'Q23d', 'Q23e', 'Q23f', 'Q23g', 'Q23h', 'Q23i', 'Q23j']]
q23_df

q23_summary_df = aggregate_q25(q23_df, **q23_scale_dict)
q23_summary_df

params_dict = {
    'title': 'Rate of Communication with Other People',
}

fig, ax = plt.subplots()
fig.set_size_inches(16, 6, forward=True)
diverging_stacked_plotter(ax, q23_summary_df, q23_scale_list, q23_labels, **params_dict)



"""# Q24b- the person that will be there for you if you felt down or depressed and wanted to talk about it"""

Q24b_persons = final_dts

Q24b = Q24b_persons ['Q24b']
Q24b_data = pd.DataFrame(Q24b)
Q24b_result = Q24b_data.value_counts(sort=True)
print(Q24b_result)

#responses that have low values (<23) are all grouped to 'Others'. it is consists of voluntary organizations, administrative staff, 
#lecturer, neighbors, colleague from my course, social networks, and more distant family member.

person = ['Others','Someone I live with','No one','Close friend','Close family member']

bar_width=0.9
# getting values against each value of y
result = [74,23,81,388,1034]

fig, ax = plt.subplots(figsize=(13,7))
plt.barh(person, result, color='#00A88F', height=bar_width)

plt.xlim(0, 1100)
plt.xticks(np.arange(0, 1101, 100))

ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(True)
ax.spines['bottom'].set_visible(False)

ax.yaxis.grid(False)
ax.xaxis.grid(True, which='major', color='grey', linestyle='dotted')
ax.set_axisbelow(True)

# setting labels
plt.ylabel("Persons", fontsize=12)
plt.xlabel("Responses", fontsize=12)
plt.title("Rate of Person there for you if you felt Down or Depressed", loc='center', fontsize=18, fontweight='bold')
plt.show()

"""# Q25(a, b, c, d, e, f, g, h, i, and j)- rate of emotions felt"""

Q25_emotions = final_dts

Q25a_joyful = Q25_emotions ['Q25a']
Q25a_data = pd.DataFrame(Q25a_joyful)
Q25a_result = Q25a_data.value_counts(sort=False)
print(Q25a_result)

Q25b_hopeful = Q25_emotions ['Q25b']
Q25b_data = pd.DataFrame(Q25b_hopeful)
Q25b_result = Q25b_data.value_counts(sort=False)
print(Q25b_result)

Q25c_proud = Q25_emotions ['Q25c']
Q25c_data = pd.DataFrame(Q25c_proud)
Q25c_result = Q25c_data.value_counts(sort=False)
print(Q25c_result)

Q25d_frustrated = Q25_emotions ['Q25d']
Q25d_data = pd.DataFrame(Q25d_frustrated)
Q25d_result = Q25d_data.value_counts(sort=False)
print(Q25d_result)

Q25e_angry = Q25_emotions ['Q25e']
Q25e_data = pd.DataFrame(Q25e_angry)
Q25e_result = Q25e_data.value_counts(sort=False)
print(Q25e_result)

Q25f_anxious = Q25_emotions ['Q25f']
Q25f_data = pd.DataFrame(Q25f_anxious)
Q25f_result = Q25f_data.value_counts(sort=False)
print(Q25f_result)

Q25g_ashamed = Q25_emotions ['Q25g']
Q25g_data = pd.DataFrame(Q25g_ashamed)
Q25g_result = Q25g_data.value_counts(sort=False)
print(Q25g_result)

Q25h_relieved = Q25_emotions ['Q25h']
Q25h_data = pd.DataFrame(Q25h_relieved)
Q25h_result = Q25h_data.value_counts(sort=False)
print(Q25h_result)

Q25i_hopeless = Q25_emotions ['Q25i']
Q25i_data = pd.DataFrame(Q25i_hopeless)
Q25i_result = Q25i_data.value_counts(sort=False)
print(Q25i_result)

Q25j_bored = Q25_emotions ['Q25j']
Q25j_data = pd.DataFrame(Q25j_bored)
Q25j_result = Q25j_data.value_counts(sort=False)
print(Q25j_result)

emotion_rate = ['Never', 'Rarely', 'Sometimes', 'Often', 'Always']
emotion_results = {
    'Joyful': [168,193,986,181,72],
    'Hopeful': [79,152,951,222,196],
    'Proud': [182,185,937,156,140],
    'Frustrated': [113,187,995,207,98],
    'Angry': [130,224,986,184,76],
    'Anxious': [122,174,972,208,124],
    'Ashamed': [1034,238,225,76,27],
    'Relieved': [142,211,1052,138,57],
    'Hopeless': [257,210,940,134,59],
    'Bored': [81,113,931,250,225],
}

def questionnaire_emotion(emotion_results, emotion_rate):
    labels = list(emotion_results.keys())
    data = np.array(list(emotion_results.values()))
    data_cum = data.cumsum(axis=1)
    middle_index = data.shape[1]//2
    offsets = data[:, range(middle_index)].sum(axis=1) + data[:, middle_index]/2

    # Color Mapping
    category_colors = plt.get_cmap('coolwarm_r')(np.linspace(0.19, 0.9, data.shape[1]))
    
    fig, ax = plt.subplots(figsize=(18,5))
    
    # Plot Bars
    for i, (colname, color) in enumerate(zip(emotion_rate, category_colors)):
        widths = data[:, i]
        starts = data_cum[:, i] - widths - offsets
        rects = ax.barh(labels, widths, left=starts, height=0.8,
                        label=colname, color=color)
    
    # Add Zero Reference Line
    ax.axvline(0, linestyle='--', color='black', alpha=0.5)
    
    # X Axis
    ax.set_xlim(-1500, 1500)
    ax.set_xticks(np.arange(-1500, 1501, 300))
    
    # Y Axis
    ax.invert_yaxis()
    
    # Remove spines
    ax.spines['right'].set_visible(False)
    ax.spines['top'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(True)

    ax.yaxis.grid(False)
    ax.xaxis.grid(True, which='major', color='grey', linestyle='dotted')
    ax.set_axisbelow(True)

    # Legend
    ax.legend(ncol=len(emotion_rate), bbox_to_anchor=(0.5,-0.29), loc='lower center', fontsize=12)
    
    #Title and xy-labels
    ax.set_title('Emotion Rate felt by College Students', loc='center', fontsize=18, fontweight='bold')
    ax.set_ylabel('Emotions', fontsize=13)
    ax.set_xlabel('Responses', fontsize=13)

    # Set Background Color
    fig.set_facecolor('#FFFFFF')

    return fig, ax

fig, ax = questionnaire_emotion(emotion_results, emotion_rate)
plt.show()

"""# Q26b- personal mental health rate"""

Q26_personal_mental_health = final_dts

Q26b_mental_health_rate = Q26_personal_mental_health ['Q26b']
Q26b_data = pd.DataFrame(Q26b_mental_health_rate)
Q26b_result = Q26b_data.value_counts(sort=False)
print(Q26b_result)

# setting concern rate values at x axis
mental_health_rate=['A little of the time', 'Some of the time', 'A good part of the time', 'Most of the time', 'All of the time']

# giving the values against each value at y axis
mental_health_result=[201,914,198,176,111]

fig, ax = plt.subplots(figsize=(13,7))
plt.bar(mental_health_rate, mental_health_result, color=['#62BEB6', '#0B9A8D', '#077368', '#034D44', '#002B24'], width=0.9)

plt.ylim(0, 1000)
plt.yticks(np.arange(0, 1001, 200))

ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.spines['bottom'].set_visible(True)

ax.yaxis.grid(True, which='major', color='grey', linestyle='dotted')
ax.xaxis.grid(False)
ax.set_axisbelow(True)
 
# setting labels
plt.xlabel("Rate", fontsize=12)
plt.ylabel("Responses", fontsize=12)  
plt.title("Personal Mental Health Concern Rate", loc='center', fontsize=18, fontweight='bold')
plt.show()

"""# Q26(a, c, d, e, f, g, h, and i)- rate of other contributors to mental health namely physical health, studying issues, future education, personal finances, family relationship, professional career in future, pandemic crisis in future, and leisure activities"""

Q26_contributors = final_dts

Q26a_physical_health = Q26_contributors ['Q26a']
Q26a_data = pd.DataFrame(Q26a_physical_health)
Q26a_result = Q26a_data.value_counts(sort=False)
print(Q26a_result)

Q26c_studying_issues = Q26_contributors ['Q26c']
Q26c_data = pd.DataFrame(Q26c_studying_issues)
Q26c_result = Q26c_data.value_counts(sort=False)
print(Q26c_result)

Q26d_future_education = Q26_contributors ['Q26d']
Q26d_data = pd.DataFrame(Q26d_future_education)
Q26d_result = Q26d_data.value_counts(sort=False)
print(Q26d_result)

Q26e_personal_finances = Q26_contributors ['Q26e']
Q26e_data = pd.DataFrame(Q26e_personal_finances)
Q26e_result = Q26e_data.value_counts(sort=False)
print(Q26e_result)

Q26f_family_relationship = Q26_contributors ['Q26f']
Q26f_data = pd.DataFrame(Q26f_family_relationship)
Q26f_result = Q26f_data.value_counts(sort=False)
print(Q26f_result)

Q26g_future_professional_career = Q26_contributors ['Q26g']
Q26g_data = pd.DataFrame(Q26g_future_professional_career)
Q26g_result = Q26g_data.value_counts(sort=False)
print(Q26g_result)

Q26h_future_pandemic_crisis = Q26_contributors ['Q26h']
Q26h_data = pd.DataFrame(Q26h_future_pandemic_crisis)
Q26h_result = Q26h_data.value_counts(sort=False)
print(Q26h_result)

Q26i_leisure_activities = Q26_contributors ['Q26i']
Q26i_data = pd.DataFrame(Q26i_leisure_activities)
Q26i_result = Q26i_data.value_counts(sort=False)
print(Q26i_result)

contributors_rate = ['A little of the time', 'Some of the time', 'A good part of the time', 'Most of the time', 'All of the time']
contrib_statement_results = {
    'Personal physical health': [204,947,212,158,79],
    'Studying issues': [93,218,209,934,146],
    'Future education': [92,182,219,928,179],
    'Personal finances': [195,867,182,185,147],
    'Family relationships': [180,867,199,183,171],
    'Professional career in the future': [100,180,217,915,188],
    'COVID-19 or similar pandemic crisis in the future': [183,930,179,195,113],
    'Leisure activities': [171,237,908,186,98],
}

def contributors_mh(contrib_statement_results, contributors_rate):
    labels = list(contrib_statement_results.keys())
    data = np.array(list(contrib_statement_results.values()))
    data_cum = data.cumsum(axis=1)
    middle_index = data.shape[1]//2
    offsets = data[:, range(middle_index)].sum(axis=1) + data[:, middle_index]/2

    # Color Mapping
    category_colors = plt.get_cmap('coolwarm_r')(np.linspace(0.19, 0.9, data.shape[1]))
    
    fig, ax = plt.subplots(figsize=(15,5.5))
    
    # Plot Bars
    for i, (colname, color) in enumerate(zip(contributors_rate, category_colors)):
        widths = data[:, i]
        starts = data_cum[:, i] - widths - offsets
        rects = ax.barh(labels, widths, left=starts, height=0.8,
                        label=colname, color=color)
    
    # Add Zero Reference Line
    ax.axvline(0, linestyle='--', color='black', alpha=0.5)
    
    # X Axis
    ax.set_xlim(-1500, 1500)
    ax.set_xticks(np.arange(-1500, 1501, 300))
    
    # Y Axis
    ax.invert_yaxis()
    
    # Remove spines
    ax.spines['right'].set_visible(False)
    ax.spines['top'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(True)

    ax.yaxis.grid(False)
    ax.xaxis.grid(True, which='major', color='grey', linestyle='dotted')
    ax.set_axisbelow(True)
    
    # Legend
    ax.legend(ncol=len(contributors_rate), bbox_to_anchor=(0.5,-0.28), loc='lower center', fontsize=12)
    
    #Title and xy-labels
    ax.set_title('Rate of Concern on the Various Contributors to Mental Health', loc='center', fontsize=18, fontweight='bold')
    ax.set_ylabel('Statements', fontsize=13)
    ax.set_xlabel('Responses', fontsize=13)

    # Set Background Color
    fig.set_facecolor('#FFFFFF')

    return fig, ax

fig, ax = contributors_mh(contrib_statement_results, contributors_rate)
plt.show()